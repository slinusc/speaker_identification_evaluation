{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperModel\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the processor and model for Whisper\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "model = WhisperModel.from_pretrained(\"openai/whisper-large\", output_hidden_states=True)\n",
    "model.to(device)\n",
    "\n",
    "def check_directories_exist(directory, layer_indices):\n",
    "    \"\"\"Prüft, ob die benötigten Verzeichnisse für jede Schicht bereits existieren.\"\"\"\n",
    "    all_exist = True\n",
    "    for index in layer_indices:\n",
    "        layer_dir = os.path.join(directory, f\"layer_{index}\")\n",
    "        if not os.path.exists(layer_dir):\n",
    "            all_exist = False\n",
    "            break\n",
    "    return all_exist\n",
    "\n",
    "def load_audio_files(input_directory, output_directory, layer_indices=[-1]):\n",
    "    \"\"\"Lädt alle MP3-Dateien im angegebenen Verzeichnis und extrahiert die Repräsentationen aus den spezifizierten Schichten.\"\"\"\n",
    "    for filename in tqdm(os.listdir(input_directory)):\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            inputs = processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs[\"input_features\"].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.encoder(input_values)\n",
    "                for index in layer_indices:\n",
    "                    hidden_states = outputs.hidden_states[index]\n",
    "                    mean_pooled_hidden_states = hidden_states.mean(dim=1)  # Mean Pooling über die Zeitdimension\n",
    "                    # creating sub directory for each layer in output directory\n",
    "                    layer_dir = os.path.join(output_directory, f\"layer_{index}\")\n",
    "                    os.makedirs(layer_dir, exist_ok=True)\n",
    "                    save_path = os.path.join(layer_dir, f\"{os.path.splitext(filename)[0]}_layer_{index}.npy\")\n",
    "                    np.save(save_path, mean_pooled_hidden_states.cpu().numpy())\n",
    "\n",
    "def process_audio_directory(input_base_directory, output_base_directory, layer_indices=range(25)):\n",
    "    \"\"\"Verarbeitet Audio-Dateien in den angegebenen Verzeichnissen und speichert die Ergebnisse im Zielverzeichnis.\"\"\"\n",
    "    for d in os.listdir(input_base_directory):\n",
    "        input_dir_path = os.path.join(input_base_directory, d)\n",
    "        output_dir_path = os.path.join(output_base_directory, d)\n",
    "        if os.path.isdir(input_dir_path) and not check_directories_exist(output_dir_path, layer_indices):\n",
    "            load_audio_files(input_dir_path, output_dir_path, layer_indices)\n",
    "\n",
    "input_directory_path = os.path.expanduser(\"/home/rag/experimental_trial/data/all_speakers_backup\")\n",
    "output_directory_path = os.path.expanduser(\"/home/rag/experimental_trial/data/all_speakers_whisper\")\n",
    "process_audio_directory(input_directory_path, output_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in train: 8880\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in validate: 1110\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in test: 1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8dec8422ff907ed644c5af9c3f985dc9bc1a6d3e4530d6d6a8e235ed6e925df3ed4953c758fc83fc43686c8b25c88961eed6e938476a53810c1f605fc8364a5b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/87ca082c21113b4a0a6929e51905d4656de77b9a5f5e109c4dd0611aee245f7043a806b6937edbc0017e0e51be91e3ff42aac1726c841dc681a7703d7105d365.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/ba90490e7cfd09c03c40a882dbe9872644db603990895296a0a6ac8caeb3bd7999e45eeb76357364279531345d69f29144bb01b1926251d9945a8b708129b763.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8d098ff5e6d3bc51b9d3c66730225f6ce0690b033f972af7aa0a96caf43952632522875b5fc20adc6b7c65bd8be4194e01ce2e3059ebe56390744eaaaed271a2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/102bd870ea99826aac39a718dec7cf73bd3d157da4ea6b16ae0d176b7c45b9ce87cbd515217748dcc21d1fd3ccb7c3d72a3e514d38876a03c3ecbb988b49bb8f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/e388932f7267ace86088080d76cc090dd8783a220cf184614e9824ab005b8faec92a73ca0beff9b650672c0d5858070cf5c9160228efa7f17a95762b944a8154.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/0920f3564af31c567fca50c113dc39ef0cc9f73add34e7259eb97c43b1227a8db683391ff97398d31b9651fb20aee149162828e07a97eb882038a7e431ba37a8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/a1d2964cf1bc6a182fde01aae04cf371c62ec85cb3b9e9af25eea84bdc62230cbc1c86b275ac45b955f5fa78a01fae9b10386123c0712c3ecb0ade1a5e15a09e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/2bbef1bc0187a697fcf575f19f36afe9492cd4de5c236a857236b9f4143148f998e443e6943ab2ac9aa3120788562754e120150016a352061238c4cd49097382.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/680583211b28aea2ac5df042b1f9e099d17415d7e44171262012ace657eac2065b9b0ad7c091c4871950c4f7e82e841bfa9bcb2e93a3cd7d55fe2177477d1827.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/d47e2fcd8b12a48dafa6dc31243d5ba55f407a2e51e58d6379dfcc8732bcab4a7fc9e8186e35eedbb0b4cc8fa1f9318e0b6c3a0e8aaff430c7ebe267b7b255e5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/da36af97f8b0ad50fa125aec0d29de2015d9371e19fd8d738ca53cb4cf50d299577d3113157313bc42fbccac9c5aca8ad691fd2189e1962c3734d8b1ea8ee979.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8b298f5dd7827a577ee0c812ff2b23ab3e43b78999c0f7da7a18d44702c78578d8c74ecc938298ece64355df48d0f181829274619908b5a3d2868d670c7b680d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/1b2c454793dfb324794af1e4a9b6cd0242f598988f50102f17948d1f2cfaf8660809eba744ef7d904b7a45ebd9db3c3aacb5461678859db16f840aca3e3c32f9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/867ba01e0bb3039c47181ea339fc1fa83980ee67d12e33cb2e138d31672d866bf1098725a0d541d09140e75020e66f452b4077b7599a081a2fca95d8fd6ad188.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/7cf3fb909f992754811526bb6bdac5f93f060d60fd9a2baced5f8065ac2f916d79988d0e96949a54abaee95cf6d20918df632123ade0c6aba4806ace02cbc124.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/5fcd688a9c1d3ab060672d47a7b5b4238e61b7a439315934071d76a1c26eac70a86495c6acb09c380add4fc2b3832eeb88b2309cd2a03e5ad0dc95b5cd66d306.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/708bcab301e28a242baad7629f7344d0cadae214aecb12368f95aa114a144b8fd231bab34eec0847adada7f4cb36c89a6ce8dbef69d776604ed4b22c573e6851.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/5b384cb8da208ccb7dfc38a9e3c89b4c9f33c943cde45864ed1dac2162e87ca6da63d80b11bf0192cbd6df6316cc21d77fc01738d26f7406a79dfe0e3742bbbe.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/7b6023cba6bd8e528551515da7ab72f0c89b9365d78fc3df1757e2592858c3cf6d54040d2d4cc38436074e3fdcb186b0ac38f446699d5fdfb2786c6c0f98c4b7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/fdcd771de285de71161382619919c9b0f7289e8ffa32e9ed3a878d5c4fd966b2cd8db30f448efa6039b1d9ac0fe70bc1aea09e98ac0d5a52a3ae2e549cd654d5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/d97dfe81579103daa4f202dc671bf263ee79cfa55f6e98da2b30f688e30f975e3e9f33875a3b3a61bf9cd3ff8eccadf201f660ecd81fb77a1dd0bede2fe4fe4c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/08aec6d0bcd372d187b60cd6296e219e7df7cb1a0fb8f5a2628cf386d83f3ccb35208ba4d6fc1ff98bae46bcaeae25182b423f8ffae7f6bc5fe5bd890c041302.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/db0c0190a7449a4f92509948aaa788bb63a03ef22a5f75f641165fe5c162c032f5184eefe6c8359cfaa3f89fd72f9b2135895c653a92015fbe154d2eb2c166d4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/938a9bae53a5ac1325a1b8b30fdf30c7d1140fefdeb11d2f4bcdfd4a022cd7e26893a0684ff1e13b820d733c7c858fe06e8aff3c4bc5d1fa0663d0d38b222e11.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/ccf07eed15f0f8cbfe0fe331c3c2569fca8cc412a8bed4eb640d61e6553d2dfa5618e5fb2d347f55a909af4a85b6a41a650be701cf4234717c748888a3502a11.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/1cc204f23198edba2ed8d149a1d11f8d908694f93fc2dca6a74e9b1e5d7f6cff44e9c731a9384d62624d4a7f78dbbfcc22161e37b39640e6270907f2b60dde5e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/5d52902ad06f8d98f4607c97e5625c5f6cb2ede0f6c27f608dfaa1e8ce0c13548560b00977800f31b8693c4b162729b51fb0844247ea77807c7cb254e1571a03.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/f43729d3598c9a165af1630e45dddefeda827a55c3b6310b636bc663cbfd924a9f0f1a654d21e23f97143567f2cb4baaa169a888c84d0c38d39ed63eb003262b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/76df246d527fd26c7ea0e15e57a0bed3ae28d46ba3e571ae3a90e6b9899a62067f57229bd347110354d58b72fe1c5a47aab095e184dd86ae7d02d4d6c17915af.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/4165052da011bfd2dc708879260ca7a50c2a1e76625a57da35fd99571914c91b7813a0aede40dfd1058e6dae6a6a687f848b262c8b9604d54fb7684f9aecb929.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/01aaec833a92078c461d065e4344bde3b819de61769b1bab333ba7e66ff445579fd32f192d731a60335218ff34ef69c388321633a969c7f0ebf66fe36fd17371.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/3d70d0f570ae3c52add5da6b42d26fdf3d5f52fed06173d69426a77bca2096555c70fdbdfb80f2e6713ef0308a345b46f1018bd9c61e9bc18659c6ad5888578f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/aa3af9ee56fe48e5a2e686ddde51253be401afa2e024aaf5744f949b92b09b02980b097f84bba1636b5fa5d3df49e286db0fb35a6778fed40cee5e0486971688.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/35b53635beaed405942a2ba185c4528883c7b226dad1970030f290ec56af00efe409c3d4088996e946a015f09021261b5767242f09aba98114fd6897c1316d9e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/0012c38bc775e2fcb1911fe28af16e080e07619dbf1a30a4b2a6f535ad5ceaa62cf0d877192b67c35786eef4a515b693014195c9d093040806273625d9cffb01.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/038f7521fc7f274f9d97de82de61ed082967dedd1c1ba80b64640eb46697f3448f4a7e5ddd80907839a9049bf5a551fda928ea5a8fd9ac036be110ebf7eaa562.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/14df567eb32cc747d09dee3495ebed358b3652fa00f2e405aae0e713a0eaf1af7e591cfea691ee68ad6fc1fa2bd8a1bb33fd8a0b313c53f305d64b38900a37fb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/7f755f1bb40a9db811cfdadb95fe6532f9f3ba163096f1719170bd1282be5248fdef82bffa7e443e58a94e215e782d61328882a5ec93e83445b5185c80c42b95.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/5226cb6951e80916fe104fc6a6a96fff9273fd50abffea2efd346440f834648c4bdad8a69c59e98a3e41a58ef8111df7f9a1f48b5da170632f55374408251681.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/c3f5ac02edb02557a2675359b88503a955410a0d2d51fbb6e3f448d413e5c2a71ca8021f2d9841546751241db834401ffd25828769fdad8c5b4289470f40999c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/c3333ddb74135ed976dbbf58760a1c9050b6278ad34d0d7e06926dccf98a5b7662d5131ec5fa7cc59008fb20fe18300c3edbf6afebeb47adedcf22f734bb3e4d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/afa0e5a12a1c9978b0278f503b0b8c89de57966a30d0ee8e93766926ae43f6e8d913fc4d33fdb2963711dfcd44051da2d8cd7ef7425a6d6a282297ac95fa510c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/52be72f726a55a68aaafe841e09b8612a93f9d14a9eb33af264bccf29e52ac29c3bdf8b72fb6132840e4ce564f0098c0333c0183a64c9e1d063349b50e930199.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/635a2aba35525baaf9b306cef4fb504867c6f09865d10bfc9718edd92b269b2d7b56df008c3f28138c4baa90ccd6b88cce3c6e9c3b2b87b6ad4a8465222fa778.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/42aebcff2653ef1e19a4fcf7f2be078639919c39cb8b9b4dee43d8a521ac02626700c6d17ec1babdcca44e83fbbf89e7130b0a56ccc6f4c432457696b1896d20.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/7dbae06ad861c4102312f7812e9822807ec4c76bfbf3652b2c26a1d45505eb6c1e38cfd3c82fe96b82f25cc5d1fb55b01726c71d6cce1d1a442f096a8911093b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/43ee18da1a80de9871f67bc611cbebf3c5f73017274ecbac8cbe56c3e70f84561afae36c184e05e2b110dc1c3078f0bf8c546ba7827981b7c7ec254d113033e2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/65f0bf4a0a43f7125110e9970cc52eba860b7f32841716ef7e0ae1d92804cd6bec7dfbb995253f708f8e064ab282b038fbdd043c6d7e0b19743662a2c300e0f7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/e18191b5b1df7c1e5523517176da9ed850c507771bd7fa47b20b7155dadb0f9082ceb40e0d811b3991768d1b3cc6c69e0c182b2df4b02e129bf5d109ba1d903b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/65f25e505434a1766ea87870986372199493b9b98c060441fc429a659353db46c562487fb9c67249bfe23604cd3fc2e08ac4f49f6549b5b652f6b736074b3626.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/9efb8f714980e10c0c72835de1dd45ac69ed777825fea78abd5406260848098abbd23df8cb678a2cc7841a4de06bacfa7ef0360907273773260ea3e094e8d9ca.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/1673cf57e725646a0d4c72c2ac2e355f487fa98826e7a8f6503653677f6778d9cb713401d0bf8efa9925fb8b693f567178d9db34d0c742b70058487dc5952840.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/b656d3db373b4fb79ea3e24507e66490d3a157d6ba00eb221d2b9a7cea78cd721a0d536c49d34cdbcf92f1786d22a7d63ebe43c5356bd176b20a73e604ef7c20.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/2d63142f42b5f00bc3b06601ca45681f5c851c6e25b002d0349e8b445a785eab3d2c650771de4d6f5c4751864b684f7000f9fe7aae5fa83a02e8d29b57b988d6.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/cccb5dccacae6f6088ddfa823e3f8fcae97dfda4fdaf73a938c2c53911dba7ce72f09b77ea568ab6b36ff1a145776ac957a9fc7a76226d31f562082230d711ec.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/fcf31138c7c88da87bc7e0c4b5bdce83012ae368d062d1464d3dc20b76d3176ef65938eaf8bf8b6581fc29093fb3c31efff291d2f092adeca337787c860b5610.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/5a0e706758654f51a1e6e3b24712ac9b03ebfccabdfefd64caed690a88e7bc441c4bef412ff667040e1c94e4ee9964bc07a01b4ca3504a80777f4b98ff4ac302.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8b04530482f70193b067ce27134208f0ca385e43c243bde099354068d98bc9376ca2b7fffdf8583b9b2b039c2c702e16df2b9af0e17d345aa1fef3370ac7fb48.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/41571be901e3b2289a3d70c09869386000043b7c88e8ab63de603e27361a56eff994fb1f8228ac54a054d9156f1dc854f7526731f2d28253e9b78895cceffd90.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/c4f44e1f1dc8fe08346d76e9e2a46485a5c16066a83e2a7611d2d1089a7bac73d100b8772ed01b8763b1c565c0f296a201b47e1868fa43e427f5fa525c24862f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/ec09bb7dd0c737940229056504da47613f4b2f339517dfaa99aa4f41df3f5d9691b9d0e530709e3433dd8f820358697ccc2abe8310b817436c6bfcc0fb188232.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8b1c5716f3a429c3a2ab32c0ee3efcd2eb52d51f051063e67da00a108933d288f69a8f9f9f7daf1ca166e0a57257702415614b8827b24197e52d7bd99f333e31.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/9afe4ab4ffa114aa7119a9b713afda08bc34a2277b9d6e4992a6c74859f8aef9ddf4322164dc99c9cd70023fb9f31041267a0df7aabd26219abf7ee82c13bc2b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/ddaa44ccc799e5842980000609b1908284a296f092e15502605a4efc63f005da035e1373768057a858bc8e3e7d13f6930b69100a6eaa04434a33e765d36a681c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/0ac3642cfb5bc382aeef2fea2e6d8102eaa2db4a85517c0e8dc917c9f73de689da447639f6929467bb910c950fc7b0e23a1e0ac93068f646ca3f2979195fb3f8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/eebef29ce3e13c32277c7483e9b9da0b6d0e04adfe47a712e8159aaaa646af53a49155f16b5924515363b936838e833d65f8fce908a14b86d6595da47f768b8a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/b6e419669763e2ae70aaed0b90b735eb3d679b93164df8a109493db3d32191b603f760183952fcdc1894d9ebe425fbd8ce11ad2809ee788fcc22895c306872a5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/18960e6ef5da384c8c3458950e357a97ad9db32e056fdae18f044744417a7c701c5f5a082ea6371fd1dd28243b60bd029e1e22654d3b7705031b90c3931039b3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/0a48e43d802ab0d09824a0920803571daf20f60311939dc726d53800c05012fe68bf0223ed958f37e996e9f44221f02d1eb4f3e85df18b90fc4b3d1981d1f5b3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/f901ca5203ea2812bc66e53cc2d05ec22ce6aeb52c61baa71feb44a64801d4aa061750ec52dbe41cf3967e1359b6ba177570f8932ff509c86be31ef003cc6365.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/1029ba54e22db6dc663d87e77a1934ea0d708a76c7d15b6b47306c5e408a689932694454220b28f13e61fafd1f6d0ad2a175ffa8585f13c891bfd37e78abd4f9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/6bebfae901b547d3845a1a73aa3a3906414b592a973a93c1c11e357505b7c0cfdbe456aed5ca862d3b2dd5f34dae48509eb6c2708808cf36392c0d8b374fbb47.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/2c3f1d44fc5e0668433ee37baf740f3d5eb7a7f7fa221ba85f53c25841c8f482ab5ad0a83d41809245a6656ce404073b71ac77944e212b8a8803499268963860.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/b603693e70511f8eb08ab7d5d7a08522b853464ec1fc757ac88e7b9fda90b8d5fe5eb9e2daad05cf79dd9a56347e9c7a61c6db2740e73d1b2aa646b814d1c172.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/fd8dd8c8e65cddb0225e76abf9c34ff58971050c01277eedf89f61d844389fde0a4fbd43cc8149b28e2519a2ff77b7a65747b998319f2d5456ade5665573121f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/35e67142c987a687a1caaa83a176f9379827cbfb2079e40bff99b1ec3fd01400d828d94d19d4f90e58af90fcc07fd7009f917ea3e54febdd826a435d0e7a098a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/79aaa83484481443688f22ca2a8df805aea45d7c814028ae973a19667fd7a918292589f47033473f269c059017155fe179f43c7316304135fadfb18784cce751.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/ed75a89bb2d6d7578ace80a5e2ad8c95621c5b3e0edc0adc7f427dcc5a387d78d5c4aeab85fd12bf211580705b90f0be1d3ea10f3a739856dbe3c7df67534aff.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_6/train/8e85dc2f51dcdb9349aacefc58863e2671fa4b7f2aa7f4ca22783bcfd3d5de8f3e8bcc41802df35c36e5926e572e1595a43707c0f254ae5fad0963d1475d953c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/9ad725716cd80cc18585d7728e00fcfe6cf32c7127d3277edbf8f1f619505de130424a3732740da461c8532f2c1990c8c04dd8d4ad27dd2b7f7b8640c40cb448.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/183a45d2035b0c7729acd4cafb4e9c035ebbfbf4ee80e6485a469007d2f0050cb7c11e698e140b9efe63796eb4965e63affb010462de41b8e1c8f94339e7ec10.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/82d79371b2d6de2acb0ce7797b125896386d7ab55b9fb31b960aa2d4195d224b337231542a47f41b58ddf100de524721e62b044639d7fd19bdae959feda0bd9b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/bc98102d2097b05732b0ae395d26c3690bc011ab4992b6be48232158076f5a5cee6c9dcbb89503926605137a34ee252543716cd415f6966c0eda8d7b10771516.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/c95cadef5f8dc603db7bac01b91d9a6b8ab5e527482d1242714e09d1cceb0848fa60971ac9832637ce82d4df1a3552272aadd2736704f43acd1dac34f07d5fa5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/f43d57c206361a82f05c8256e66cdebd2a1721e7e469aeb69273d357852545a62af336259dbc1493a8ca5a68613c9eec25fcb5ff0674e0a32ab47c66d8cec4ce.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/d841c25fabc6e6d22cb2d8eaeca0916776d8865c89683d48458ef501fd34aeff27a8ce7d787107ca7da74ce543894db540e460d679fa2b24644458e33cdd67a1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/3fc7454f158f6502839cac26013c37f7718fa1891b4e0ff387af783666b3b2c3f52ef138d2a6111a7a3040c2eee87086f0a70e1d069b8bf3fea448a29ef49462.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/0ddbb17ea3483c5e155ec6fe218610da44eb61d54319d1052f56c89c9735796dd7bf96dded578d2f691bed4c82ac27e91b8e9e2960986cc8644d7b82cfb8cce7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/147315e98da64b9dccd34f4b8f1e864fa316a4971bbdfecacab3553216a2788d8a8f5b507f7a385429300acb293296d952e0d2fd68b32b2bce5c63bcd6cee428.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/8d1fb9ec7cc63670d6955d4edae1e176ccf72f76e1ac353edc5d29257906e618ccde118860f63321ce428bf2e4682b21d3715720b2cf5451409fcda400419ff1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/7e948b99a8fb254b83a5ddd2044cc8b0abeb4a90940fe379582b781117c805c24fc70f84691dc99bb0cac34fc8a95c7dd53b0cbada039bde7c564ada5b13d36b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/415c4d03ac95aacddc07ddde0176d6ac5f166038ccde40e9c41181e98cd522531c89b896e3929063c0aa9b7fdda64189fdcefd545c758ec245d0012d208a6217.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/f3669e4ac40153d69d53c0028e6c85e69619faf27d714a0a6935c16464a5783c6944eb38248d94e16704acaada441cf8d0f17ef4ad20ee2faa48a5bace1462d8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/eae24ed490b4f475503d6f76f7890a4d126afc639a54d6b2388967de97d3639edc49d69fe47b1b9b42adc258fe49e307cfd2d4db7df9218a2298bf1f034e1ba6.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/3708fc8fd6b3a29b033a098fdbbd69d316c06a84545adf36720f7950e888f23e137561bde61d8e5be17882ee85f40f51b72efef761028fbc29f657d23d8a4dca.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/9f5b86267532e6c61a7d0063460a705c23291d163019211305d889c621bcc67707752e4719c590c6b4676c968b55b5ca3fe714cd7f2ea4cd5db48ba90cf15148.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/6c39150d5fe7a993416d2851086fda04867f2ebd2269fc0cf96ed63ee0e2731ad1918e40e415e35c860568d8b0329ad36d0f7a944162f66e128a9c8ccc743dbf.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/61035f9b7018336b47f4c990a42b9e023812a53b11b6cde60367c50624e868f1ebaea292cd1389c228e4bd8ef67e8592c21fe6122dfb5f70170fb5554ce4455b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/94378cef17372ca712686e2fa3e89353aeaf3a85b0174778f0892b1b7ab0664dca36442875f860cb2b88bc7d712b4daea61b9ce2af77901718c4d68a314eed5a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/5e616a70dbcc6596985c28a4a016625293aa9a6e5e1ac64981a08e8aabd05ce040044cdd43f25e923bb14bd21c9fb997c0904c9f6e2ff8f8a195a60e451f4328.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/fdd33a9b220596f31e81bfb0497b1444bcb5478883d3db2b5d32934288fa966cabc59505ac0b3a81a8544a4aedb382c2c97250a821fdb1255cf65e35592b3722.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/a76904ced362414c03c50e666e0eaf7179e4c5de3ce93dd0b9c23b992c8ca945012bf047fae6db98fe6e4e419541a9695888fb160f86edbda30969b8554e6464.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/94d4b96bf232cd7a3bee3404fcc28a06f298dda00482ebfda4c818ccd76bd8ba203a0faf5e9cfb9e8ed499b1f6bb6795f4295574a3a2013861531f6c413e7899.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/ed5e4804100bf7cf7036cb37730bbecc6923d7e82d582c18ff945b50a0b560af40d3f90f788b21c23427c5ea9cefd7a73e9bfa4b5420efa5ad78aa2ac162bf29.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/858365e7a61fb97a74d6ec7b0c7f81bd7169f0754201c0bb220e735729bb312d508ca7f102303a820960a28e414f4cdaf104bb8edd07cddd446ef561d62c26a9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/2754f3e0d83a0bf654d6748c204cdf9fd722187a6138ae9f1c355d50390e1432a3532b64b64733149aa5431a85516eff4520883c6431fcfb01647eb8720c9f96.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/a75d5777a23e8793247792c132326914bc6c5b77814855d595118083a9e63d682108bc7dc5f0df4cce6cdf0484f5ec3dbff97b6f1256be09a0b16f15277e2ecd.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/278f09a3a86a44b655f71979d2d0319c9c00dbaa87936e4c333b2e44960b9b43f3be01bf23f79d5e3741f62ea9154fe623b9592095e82d9dc1557e1f6a6245de.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/2de1575bb01bf1505f6139059c5384450c29b42ffe39b44fd03ae23a01bc54c7c944a3b959fb73772740aee1326cb238beafba405d8e13168afdc620aaff18b5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/baad4474bb0ee805d9301e92f87e867d2384705022308b7c83377ae4fba3bed696ddd73c740248547def5270cb46b2b94f62220cc9d2efc9ea2ebf278122c722.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/1f51f4fbde21d3586d3c5b8cb938261048c538fe7f5cc9a904c4121353c0899a246d112ec348ed710408663ea5e66acb4d75a3f1ee6675f2269c09f2014886f5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/22e02b890e9084dfaae3f13c33793234261db610ff47393832e610f957fb1af276b49deb10ed2ee1fec671a066f6fba992d728b55cfd3247b37843facbf71658.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/c0192d1b7570d59dc88b31c69512f6283ea45236d2489e947453dc20caf16f060d8178d790536157fa47be3a702b85a4f89bb1f96093cfe9986f3881ab27a166.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/e779908e76169db5acc83ab176b691dda1f4aed10544088b99862634bef60d59592314cb8d1647f5f39042980e0d0f9f5aca057b585ba7d01961305422a84604.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/50f96adfcd0fc4096d712756ed3790a308322f11b5f23e63a207f63590a3e83d0c7f595190c6fa16970c35a32910707a2a6a61da9bc24034bd90def8654b6177.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/7c433044cc987302aa8d1c9fc2c981a313dfd14c87545548961276a044c9a61184f76e0c2c01173db7d492de9555069af54bbeb6ee3fd4e9f16cadcc3f68ee8d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/d88ab8de2cdaea5e364b8d54c5eb5c9ad4e2ee4f7298982fd2a5e9a9f2a58fb122921ca5e51c693b94c16f99ac7676707ae548ee8e0a1bdcc00cb0483e411243.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/335eba41d7e0d6abdbfe64051e27a3d244863b506b88aaccc5361196a2fdb51e4eac6a5dbc06f626aeab6fdcaab46459ff800a4b8310ed79cfe426b66cb74b09.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/aa92760fe10a0659c6934e04e4372cc11a23a59e166c9b5d0e593fc5fcffcd7166c0b0bf802d83801d763de56dd30351fa8fb4e93cb950b6d766abc22e811d92.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/0934b4040122eff493a798b2265d7d1006880288cd3e46efffd3de5d06d955110b97ae9bdc64a78f11094ba0727c82593793e3aa106c1ad94d3b38df7180fd45.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/eab51cdddb911a103510d930d3c0ffbc8b1a61be88b70f7e0f8d15f87e172c80ea7bfd0c0c81ca091150d6a3aa32a1a3e58ff3ec12087fde6daec789392b25ed.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/7b6f2d0ebceb02f7b0d1182e981241015d25824780ffd2813501c943aff9df230c3b1941990bbf9489e90812439d75572e9f72e71cc18e00256943278031f6ba.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/0218296a8ef168f489a13425c3bf09f7c766aa2697f69228fa5ab2e649cf85011be5260489a76aab46dffd7beb52edbad09515fb578144e533a12f36a3897f25.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/fd383bb8901a47f552f52ea564bfff97e7d1ac50f4a3e706c04074aa2283cdab1cd66457ff8cb636b49cd0a27abc4f6725f16ddd482dad4bc116e1de9d493090.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/99ad6ab3677930c4db7a3f70e43adb03cd881e63a797335492097f978afe5b0281a9e7e2ba4faf4464efe5e1b77b3066c2d218901759883c39df12ec67eac2e5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/645b236d54d80ac7c9e3b72165d9b8aeebec56b52d8df360db8f61e56db96b4f9ec1ae0a7a7abb1da28974f9728b7a4d3ee7ea2a8994f344571118875c4f354a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/5eacc1564fbcdbfe0cf49a067def55ff6152e3bc3a3804cfe3ec57cde3da824c42d5801d51113d450b49c9e7ff8f4edf7d84969b04540ee560ec596985a2b450.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/1976ecdecf863af5d01b588a561df0ca16dea3f962f81482b9653e38c304a357d616e29e098dd708a06077bde3cf24350fa9e6fb409d3c5326fc8f6242be5c6f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/8caa68ab1913a571b9c3d77f44848bca63bc8ea03aa7db8cd7f44fc1f5da1f13f56d13f17fe446caf9525ea0d4456e1f0b95c259af1fa8fb045fdbd4bd7f8ab1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/ac3764c178b8d5234cdf805e3e1b55f403010073b44d5be4049c512cdb83b926f7873cc5478a7df7b88a76a6fd1d8f3100abcd057690cf0713882d94476596e3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/e4d1c81ea95f625cfd487c4b494e459e7a1cae19a0bcca65500e56efe81cab7979423747600a17d0fa8f76a3197e37439f0b3425e80c976a8c5ceab93444c818.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/fac6c6c5aa386b4077a81a57a9ad34b1f537570609c2b570426c0db67e6a13dadb19e67e060b058dc080ef88cd40db13612777909c35006b37a60af340eb638b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/cfc5f13df34f2e8beb1b7c8db2391d440bee75c43af6d3c99c2b0e99e3be9f870d03873d73833575c9833d75e0336447ed3737ba2ea1e1c3d045d3715145247d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/1b87a111dc186f974f87cb6d2b8f48d0f563601ccdc8b07509ac5c338cf8ddc3552d11b57c155a0db772bf8e1f30621c61ae0b5e736203dc7eebcf188a87d556.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/456a38fb79617b8c0d06b70c7eb1d218a1a0062b642aacf2bd794a59d6c179235c2e627a5bc2fe3e3f9eb76818c24dffbac9225604909047954512f6e7816502.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/d9e9a63455167b7ee328ca92c23abdfc801087ad0daf8ae91ce498e0707da4f0ee38e9453a7156a7d9873f13009d86e85a659e9e0b0bcdba3ea3c3681ff85ee3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/b9a1e0f977291ffd34cc501555bbef2d563e1c6041223c242a97546d5b863f512384ce996529f0c309b54b45da733ac08e201485727c1c6f3e6449de083d1f33.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/f92263b09b8ba0c93fc3a402b1cabdaa3dfefce14de96e87ffdd1d4f774f73e8c2d282ce34f3b9710c5ae09689e7abaf8447d2b32f5aa353194e223ab86f4ea2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/213e37a7ce0b6286b4651ac5db81dcfeee412d7c312758ce7f0988de107a58bfe6a12abd9e9eafa56c0dc356ceb7b68cbd20c8719217b2e907263be0fcd7a144.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/076708356cac41f745603030561a9c6a09b9fad5f51cbf20f5d9b3b143c51a1957080c83393195b16b9d5d0dd626e5c5c5ab8b5955380ffcc02d92b63ee3d839.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/cf0e4f2907776007581de727ad97f02c11044d31bfd4d0cc7bb284b5031cb6e597119974c1b90a50a3bfa0b66f93845b13847dc5c93feb363ed2f12972aa7908.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/7d84c478fc2228f20129858fde5f7ad9d345683f93bf80005f870581351962b5962b79781c4ab009212b4183688e105025c6c50775e78b73fd625453368fd31c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/f76eb76354fd0430928d57635c3c3929af6db758638b9fe6ba9ff07c25105a5f46963b86193b19770f8a85226699bd02e5996a2920da0c87d5579a79c9e3b7c9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/e19a33bb4c7f4d140ef23de991e713022e0b6b5b9d05cdadec8a2104e9f7f833b3d19165f76734aa8c8a7f2267d56ffc0a10b9641f226d315230d04b496b6c55.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/41c0400ebffee2dcc4df471bda838380758e921bcc8a2dc345fdf830a4cf3d62055833fa68187264999b60cabf12e52cd2ee20ff6eab1a4ed5f62de1fe310ab3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/c7246e12fe7944ac13f0d79a0d3357efffb4ddbc7eab0c6d28350f4de0ef4dafb06f939145bc18b1c9063d395572b26f3325628b61558e7665933f9c457c7125.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/c41ea15a7fac974c570bd13c7a4048d7262bd5f50c312f2e05c5e380f4eefc8f4bc1321a0c136c4671653ac613deb84098e3e9423a0c4dea680104c19ac3d3d8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/e073f3a8467c239174941f9f6b5dfbe8529c68f5e7175e987a710d30cfb01c715a908d9f9ad0a65cac06cff45a007e13d9903738529c3c249120b5f2431a809d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/88e0b1e1688e5bd8b0433b69a0f46cc86ad227b7c2a13f54a2e7c1a0583a0fe4eae7a252e72037dbcfce3a444bb7c493162a6c0eec4595ca809f5b2ea74fcf45.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/566cbb4edcbdb5358b6a33417dd005a33efc7b944bf26a1151237e679be1a19e7dc2398f55037db2dfb1bdc42efcdacb7ea16aa38e9ca5583efef0baaf0ac08b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/2859019885d4f44d008bd98e03d50fa75a74df6d65fae96458480cf761e13baa11230b2f73539d86e06ef0801e1166d4bd2dbf6f896119574665e08807320d75.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/64685e5809cc5fa306f4246f33fe325cec7dec62e9bcd4fbd5f773374730bd7d8218bafbb774d374838a9ce6a7964c7269e1cc0bb97524ae4dfd729d78d9334b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/cc19e8ff8c44b31ff97661f38dd5fa56160875d749fbba3a17d9797e909b85d2038ee28a01d7e3a9e61bc2a811ebc465823ff81381b71575a74a9e70f74d6bd1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/08423d5ac28014814150eebbfde6663f9372569a53513159209e5fb2c320b2c931906e121fc53216f76e4a2b4ee33af1fe4179a718abee6a246c70133bff1e09.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/94fec49900e0e99fe23147e993a1bb32e1f2de0dd8f4ae96089a707586dc4b01326977f8ba201e2921c745797322618a946e24e595cac4d388a1147d5b5a237d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/ed09855e6cbde42a896dfa625513ab6ae2b6ea96fe5a889d90ae18a4d0b09a38e2d739650fd35638aa2106d877ee0803c0d223eb4845bcdd42b27b882cfbd46a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/b331dc13ea6645ef195c48ec7dbd48f87c04a1f0aadf33f8dc0dcdb39586a63735a1921337e14a52d07be51ebb4cab3ea334d10c930e3c3af6ac7c9cf9f1a994.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/92ed62077be9f7e1169fa74521d41fa9eb1648d49d585f3db4a83e31e6798e509bcfb06aa72b6d10b48861bd1018556a1f286f6b9ef899b1e6b8d04eafda4f8c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_156/train/c73201e4d3d8e585cb8a69dc047cc3b70a41eb88287b51dce8b514186cfd677ae1b84ffd35458e48472e7a9787b16172d50353361af00756fb23c84616041f77.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/6d204e29d0e0f29ab2bcfc8336c9e4f63792fc0e39c9d5aed9d1a8a7b2a81171ba8481f74224dd4d5705e6f008a67d8868d999b0cef45e32c8921c5b096e061b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/c5f064a98f882090a98e6f04c936fce15742e165b74834619ea352d0884a0b947c0248877dc3fb960440cdde4017844feb3d331a91dac238cafb93b743b43b0c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/033837a57aa1bac1033cbd3fc2c8384b6f4b8153c48bfb8b8c6843255eb7ce9ec25389f701a8701c3f1ea9651c0335fa7d5f753dabee71de0932f0ba2d988bb7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/7c3f41dbd57435d529ff02dcb6b6d4824a0570445c06c6d12b230bd641d0473980c4485003ef248b668461168bde16258c649a8c6c6d183c13b0b741731a3e6c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/06de192daf720d9439ef9a76578363ba7e8370e61234aece489945234da359ba271178e1ddffc698c709fcc88806872a8365f6e2daafed722e816f660e8c828b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/f52cc324750f1e1e38ce5af6a6821fa3ad055e93c39627e12804cfb47c30e05820f65de8e5d55aa31cf5b56bbbc08525eba45682465862584aac80448b0c9097.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/cca1c0a65924d8c968cdd2108fc6b270d7afa837aa8487a4bd16bbd98d1e5f87c77497a8eec9f1175eba9e8b2fff2c654e26bb1f349aece3bf3b1694fe3de800.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/cfcd23c1b6343fb85b6f1d597e74554e87306c67da37955e4f974ec58642a2e8d69154a241837cf5661d9d01aa49ed1d905d564fdc8f4df0126c3f1b190145c6.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/92d4a4c7ec9bf275c7b74e674ada6c5a3e322354c842877aa107f7416f947ae46e141a525e3fa193264aa08538d6751c3ef21460be7b7a53845d1bfccde560b5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/2b1194ffd1487733b66f62c97f2629a41387e709c59a9de424bb25f663f5e91e54da2927c36b21e00cd6f0ec8dc81f37bf221e8d8d4f2c759a579ac8507456f5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/0c7981b4262d75fdda980932155b76c039f377bad96fce2e44adf13dcfbd596e3fe86eaaf6f1a836e296ba1660e2cecf2a92aea5c3d42f4bdc6dd45ec12e22da.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/04eb720311399ebf8a866954d141c876eaf806ff979a72f242ce972e37070ade0976933b2cca788ead4af99d6878739023bc72fa82dc90478cb4864d5dddac67.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/07e44539a3ea0f60dba0d13ec96e97c3e8e1a7700615489317d1972627b0dce9ee013c9ff0bd09b08e2cd48bb8dd609efbbbce72209846d5ae66c96310a6c11f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/14babffac15cd99b6ad70f0d02c30c6eab81461e00d0a832915b9205e90bfd437b96698bd9e9e255e083ef3d11bf60452ced491687e52fe8ed78d57c5b9b2f77.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/a2b73f5a67ff668a59b2a14b80c73866b8af93e6bc3d33956dc78da238de73ae0e15c453e417bdbfdd2a14a019121944e3392ec1b289569fd9940f8b6dcadf09.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/12933141c92c0d4dc4731ed3b394ac30913ef13fbcde39dc5d2163fbc51666caabe2249627ec88f2d81145d71fbdcc93c6a895226fc88dc41d21e7ef6694fc3f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/26f00038f8a42ca9c1b2a0da2bf62b8d89f0e503471398f90bd5639bc84274b1536ad339ce93ef15016dfe453f0dea91c8d08630677840ab71a9163169f5c06e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/8f6e97d073eca31a0e53d9813b2e7c14d3465987ddb1436a097950d8194a976d4bab0d3acfcdabbb1b4d07a75d3ff85f73d4be6c459dde3f6b3298387420aeee.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/bc1e1b0b1fe4ba19aea2c5f72f2394e0f5e3939b20039ad8434f2adac516bb65362c355a52263075b1452d550964aab4fc77b18b33b13717177003de16b9140d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/1141eac88bdd1ca3ade808f4ae90ab79eb0a045229353dfa229f1135af0f7fa7923e6b0981b215bf0acb95d61ffc8e74d26151916880769e8b0bbce9fd8a9423.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/9ab096c0e3163ac500f9525e96b41a858176b76f88333085995d65b2cba41432210607fddef92ff5954dbd0c404d7c2e9cc580159228b3a9319ea844b786d5b8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/6169cd3b330515caf24717d8fa33834c35468593e3f0506364f6e0da8bcf5ad71b11cb9f753d5756b651e8ab41a9c78ca9cb823fb053ddd993287ed491a3fe90.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/f431599d6238f9c850d9aad2d1621804f26ebbb50737a545857df97aaee23792a65feb7c868cdf94a0aa7f75a32c35481305e7f3bf4400835364587b0f4c8833.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/b98761632183225ecca11bec0d6509383be667af7686ab78a1b721fbda988ce3510df2e68acd95159977566a486358449ef7b4a8b7648cc5a067477901261994.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/439e0be261d2334e7738a66327e646f22440b2afe78aa8e0c0586ae3a838ed7d5c59bc6e72811f24627a51c1ee2ae0eab71c4708253a85357ff8559ee33f4057.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/248d1ec911ac315f6b1717b3d696e6b25685ddc58d6b7f95b6560f3ba6ec0a25dc2ca2ca09c438b417fa4fb041bbb18c9863a4055ccfee8ecf76b80f95faad35.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/d06dc94e59fd7eb6f6154c7868209825f5a6faef8ea5ee8f266f9640d33ef01d3e92b7cf605e6db0f6d3f435247d54becc3af8fd29f0939849fac5fee0af5bac.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/47c5eec991b9c4d874bf014d7d7366680d3d123a9e9346d35f00400bfeca26136d742404c3e02a4a7e6bb511cb86630a9f657b716f656088e4a4260670f0e153.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/a6ef52ecd814aa60796b2048e973e8c95a80908f3a39c70e73340dc4537eb36c9de356197ffdf960b65b3cce280a9be6d7bf2c40fd68b4d1eb0ac80914a2b34b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/3c88656af2fbbe28ca730d3f1d084be156e8c0b8c91d6b695da2f526c632093d4152091ec82c391da79fae2d71ae7e2cd591d92673718c1813b409d6e87e79db.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/d72f1812eb8d98627ffc76e227bda4f68ddd6d9520e392d279ee3a1fd3f693945c15fe57833c2f8265fff93862cd234332440a711bc66ffff690a80838e8d3b4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/96c658f913101fd91532a61280952547d5d92e67966361aa3c934e59a291fb1cac71ccccf119f72bb1fa339d83553cf327075c1701ad777bfd1ba84d73316417.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/86795502d0ffaef9cf158757195fe480b31e2f94f2496de27f0cfb895291533d0a848aa2c23052d1828fd42d59708f8f29b58d6af1042b59972545b1bdf50c63.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/93198cbcbaee1f33002a5a2baa7e03c9a0bfa1dbb856f20c06101dad8170021cf0894b3b33644f114282467896bb390641b418410de990269fa07fc6963ea6bc.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/9760fa8c4bb002bb61eb07ea8edbe477426534cb8cd07d523f0e4638184f7511200a48df3cc7cdc3ae4e80d0b0b5a4ca7410804b143a61dc9a47079bf357b36d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/ce1d4b526b8da7bac7b85a1c062895e33635000611f8cfac9f7fac8fad5d482e4d88e135c76cbdfe2bb6e24da484665d55a0db3bc603729c24ad7c5fc26de839.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/7aaf8c55f10280e0b7f9428c3d8ebb341064f7ac8200879a607460fc42671a5fda17f74765010e8b4a37f9c37ef360e80eb433fcc799214101075be3631e1acb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/8e356f18748302f50244fab49e523245c2a0371a45824e76566f82f45a344b6ed78e30fbbd26556f5d2bd72a359b31f01c7eb45b56ce9701aea3318cad214683.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/28744044f67df33c517f21a3145238967546bcc84f676f14a0b35e93e44a636d6e22ccfca936a1474ed3f37d3bed1744daea12a95afe4e02376250a346f3556b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/7eedf4c20e7ff4207c31c8a1496133e8fc5c1ce84a5297eeb2204bf34cd026f697df5f515a3a1394757c6d614ebad1c1bfdf9d9e367efd2adf8bcc4a25326613.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/a93e3501d464812bcd432f34a30573d48d453e23becd36cb745412bb543349be2f76ba9de90d909d9e6d5c4b802c70592785cb712a7438b6dbce6746f867b0e2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/256507f99865f7389f1579e5667dd059cd918c246b0f630b218fadcda63e95e493e6e164ac6f020c0d2fdd3a79be8b56b7b4dcf59c289066f720a127074b0076.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/be0e0af230f9c4d899a414b1f745b00783352f52fdc7afcd8f32177314abe222eb22d2c2cd0c428659c1d9aa39fab94b3ac3420f701f2e841ce7161c3c0328ef.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/f7ddab1380aeb516e126ac2f384c33965f72d84d5296fa3c97ebcd29de724da984d2ae97dad731f76c832dd3bf59189276d295eae9861e673e47c23190e3b1e5.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/c26d9487f1acfe7fcde88de98991c47b53f8947bc2a94f4aaa318e8b999dae4d0bb0dc337351fd98bdf205553e7465662d00ce08c510201cd46e2286a7e5e468.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/46a6ee378537aab332c3659d3c33fa3b05420c3788c056dbb32d25b54bc04c506ffb95694fb3bd7888447fcfdad620b96d9d0934fc46af3b8604cb77544fa1e8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/f59566f78a0566eaf352d2e66206d197e026d25da530a61e7413325d2ad1b72ac3edd8c649fee02c6ff247fc5f5009c36e10ee2227b88147214cb668b9a4f2f4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/203db3a776215eb684054dbf55c41bc15aa37dfa61a1d0337ed4f75be3de2e09f9a0ad62b80c7bef63867acb369abb4638c8b6799650726fada3babb18cbcf24.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/dc6ccddf56fae2804dcc95190ed2e06116144eeddd7a5c4a8c02e30858add14a7128598475eb823183999ab0592c4ae3663e008d3d36f6b1f37d386a290d7fad.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/380e92f0ee54ae3797e87720ac620e8da791eff8ec9dee7e040b25893c5bae9fb076d4868e89771431605f4f324e01758b36947b82c53ed0aec3887682283df7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/042bd0e373512ec4bd81390e1ed1e7971ead8a5c64966a79339b65f7b9c431569c9d6ed50bdc9bcf564e37b5dcce9e96c0c935b5c4372e12bcb8cac6e08b11d2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/c7bfd83d6eba0a5efc37c287cb39674a8ebeee2416c233458da9526fa2b6d92c806b779264d69b4be81ead02a6cb3e73cc3aa784801324ccca3b242d1a87049b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/59a79fcb7c69cf3ed176585ff1b572ad8de6576d1f2d03bf21a2a402059bff9501e7440679e64c53cab08bdb3b821221f0cc52b161ecb1292a7abd753ea13860.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/2732d94ed39aae8d7a8347965b899280d22b626c69e0f4aa7fe6acaba1409f1ddcad4d6479d13c98d4703f55560c104dcdb4fb59e97712c967ffc30eed1cdceb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/b14b4f7e6a1f3e3318e6af921b6e52166542fbe084bccd1b10f6bd209dc854a83b953a2a59a14d182a0f296ce70db01adb5b5bfb922068ca10f3e27eeafa663d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/b8582c5f54775cd348021b67a8d606d1028b2377b9305c59936bd0026803c0989b4a8bb152b85e6b813af36941844b9d622c6184b1f835f3cfb99fd8bac1903b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/1f3e84379a15b6bb1512793657265e561d63c7319c40db2cac483edde25f731148035be14b0a201f652a8de4d5f6826939e2d1bed4f0b3300a295dbdb6a9d90c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/6d8d44a570d0d9998e2acb90f2e072594474ca006286cc90e3c838c28f525b0c5cf36714433eaabb567b265d9e2797683b6a33b5ea7f157a66096295ac5b84e2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/cb3ff653e96f88907973581668b555a12ab027ac76dc6b7321df025ed17c7ae868bd31a256e4498cafafbf9717d5e3abfe60ba1317eddf16c97dcaf4c1ec5400.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/c587225a231a3cad76836c527e39e9dd22d54ecbbee80734ab8ad3c8704c8c0dfd900def266294f04011f507c3ea26839b3884d52183d2f13dbbade033c3dd14.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/cbef962496664d7fdf721c922ff5c67c739124e638c7a1c65b23a8d15429e34b8162c9d8a2ca8e7647bd00d68090bb7f306c77280b349232874b1687b2ebed86.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/1712fad734ce8f1092b57bd63bc5d3c1209a4656b2143586436f62c5c459af96fffd3ffa8962a7d1e88501f10732743372a31db3021d22d85ea675ca0594ecab.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/af94d02fb163ce1015e826df40acb7469406e79d7728988e5234ef712da9d5494cf5865f85232959a7b80236487ca7cae52529cd9f0104c4c51575d75af5e1db.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/ae225457fad55d2942475e0d6d4fc190accbfe9e21021f0ad62ce358631427a750a4b16db16016c5c6cf954654a377e760216b663563cadae21da020323610ff.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/1ba7a550981d7bfffdb85b1cc4f8d7e95f58b69b09116ad4f468c9f851eec9a0bce51ab7f19eb7ea8f18fcf3e36c4ac624d3fd4fc081527ee4378c5a1e58f8be.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/aaa618b2639bf4d72ca5ee7f29c8e06987a26af6923f6a414dc13d5392beb6771ea43d4de781aca9eb46091a6ba961a48cd203aa3dd200c91263ab7e4739abd0.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/83ca0c0739794d3550ac0b5342d0cb77984e9bcc2a4e25f44612e4c07efd85cc5c382ba8dc98df9811ffedf07b5bde056648ee2c3fbd373ea0a95e8b22413000.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/77faa97ba349bc65ff71131c37b2285fb3c88f3f4d24d2e5c375e621743171acf7d0aecc432b88a24053e1dcfc9da8cc67cb227f07ddf621e89829e85f8c8b2b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/a3310100460025719837e9005bfc0eb18712fd1e4feaf888f3107ff8a3654299267588cececbc8668092341872c2c5ee3f2bbbd047d1cc8ec1a48b1ab35da663.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/a6f2a32cc960e22c0b5f260a12fa90f9fc45384190b6d424739688758214c2e4cf5b85bd3d30b35cf9d8fe8a4d14743b357687808b8042fb1c0d15f451087108.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/d7470c0e16a4ceffaf73f9d7a7507813a2e1014afd6e1aa7e6ece79b83d19d87436024ee9f401e24d0a0ba1dfaf2d3b1b0cdc25df482a835966179cdb3123957.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/40d1eb5b3626d0666675fafdfb599b2f9d01b12c99d9fe01f8ea6ac7908fee69ffb7b653bc66a9ead7215bd936365909500b682538adb3c8c580bd18a702b229.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/e7003f8c33e2c14cfa161916c368f9eb137dda65d13d5a6f5f5a2078612ebc1667888e0af5ad0581f8418e6ec0a915bb3d56da9434cf83a048c336086bad95ba.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/abb1e36e59ceb1e8f5a907430f8e53817efade9e994a0b08059c29144fc03761afdb960fd09d08faa357319ece2bc9a857aa0f3ad6049b75f63787bad94e4bbf.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/6d796504c323e80406bb560eadbb27325268e88df8d5d3a3ddece71bcfc748ca730de6d23f20b45827bd920785f43583a380fd623b55d45755e2d97aaaf92a2c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/ac2aef2bbbd7fd8f564d90ce5557592674b1f7a33f36607c25571b7b28357d9c54d7dc0a9db64902552566a3086c11d1f9b2d555cb6d285e7a70b722221f2718.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/781aec5516a32cc6bb060a6a5bde3c0bed93e2fa473a67c2dee35c2b0a2f01d95bdaec63ee0f7d903c53664ee573afaddff0a9321d7142a2a420623633746330.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/719459d3d137442592ca1f39753550fcfdeedf6f47ab8f8d92ae5d8423a313bcd10243b0f8ed6b4b8c4fc524c145dfb0308f2c84dc5b5a4d499a1a1516ecec80.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/428fa71fb38abe2e7d61237b493142d30685e3f6a947be423a7438088404e697ef4a3089b21d58e4ecf2dd25c3e4269763f7ab45a866490ecf3b5416a312c86e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_22/train/9078d657e719cec72d8126ba3ba6fb8db30bc805b920d30597de7199ccd8591805739f22c70c9fb6dfe9580e405f09463312d2d0dd597516790e05f63ded8b5b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/cff7d766d36dfeeb4aa07044ae615e27a36d271620ed7051fe5e190a6f52b4440f9518da454df079da39d205247ac6a42788c8aff0591a716242b02e6743e1b9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/c23ecac23405bd0c6b30b7ed4cb890715684539bc133fa76cf154c707a5befd4eb1530c17687852ec8c9dd69f13d83439335f19e4867a0baf9c36ef142475751.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/96ae2bd23c0ce840debb34376cec923766cdf1bb8ec300380c6ab086d829c187ba77158a26f715de6093ac58d896c97f94e140ead33271359dc0081968de0787.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/285c1289a8d392cc16ff0febe88413af3da782de2c73635d0facca0211c53c65ae380b7b3193f01bc8678f00b749d191bc597ebaaacc51308bc6b295539275f9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/e67b203602e4c49029a8feefb3a8f87e646255d3f75b2e4d4e8ded4e6b852deb9cf1db726e7ed850216119d9d70e38eda7075bd1791bd85820dad247c3b220df.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/1eb6c1b98ecf98d3284510183993748d3e738a40b8dab510682ffef9052e8ea04094e44264e7ce2bba930299feef5c4040472fb39fdadfb9b2e615b931bd7955.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/806ebbd4a30d6dff341f5dba6cad5627dddbb90b5fffbc9b3b56ac903ebe2b25ac3b2f9392fe81176a8ff807d4a227840715c995345db2f417cfdbbd06698560.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/20acff8df757217939badde36c2f61d3ff2049d39bfeda83c1a7934a576d39265051388aea40be8848331c930f7f1f96297a8b55f829f0c8da4bc13a2ef47565.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/2a79c7577178677ffe39ebed3dde238ff1ca7d09f70dc8e7e6f98a507d69b4ec07426def4c828705c93811bb06a5abbb4ed3a4ba35b16fe4db74dafa91ba5313.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/c22152406fc648cb2e9e7c55b2035af11544d4e2f7efad8976aa0e5beaeee61391669997702686cbabedfd5771ad239d7fa1c754569233f8c0d5630ee9eb1c4b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/80f3d609a7f7ec3277039bc99ad35cd74a1fad2d0e14ebd5340233fee861c30decfcbe76b9f18d1dce3c1a8a1a717d15f075c520e2f13ab7b258ef866690c9b4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/494a4ed47c4e032577f363ee798b96c2db73efd0394077b1a54b76c9cf34ef1cfe56d7544650d2d1a7929d9b5a5a7a1b0b73f0bbf41d9ca48b403a4f5b43998b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/67194261952f849c5de6c32cba708d2e01e3b333f64a9519dd840dad5df25277338a6a2620949ae839f441b8c6133ab03b23404d67f26e730c652310c06ddbc1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/3f40a7a1a94748a6684371712e1412752c3a5fe055ec2c33b6a6c841330d2c1f9e91a3a6ce9628c7864ea47964de91798595f250096817dd20edbd492e9c0dc2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/f30243591a5d4f8b7c91b309c6f013c48667c7c9d3975652a237fb06f3905d2a75d01c38089733b74395e7894148abedd77455a025ec9b970d7d5bffcf9279e6.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/f456ca8112a6ceaa97a64748febefae35a7f2282efd8f7f75d3beadd6156e3bfe2120e21c9ac419c3f9dcd0409c8a2b9f3d4278b62c73d7edbb7b0d223beb0f2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/5d50edafc2005f23b61c0251064b93f4a04b4505eaa207a7333f12afcc32ed0bdbc5458865b276c6fcc5943851ee13564f341be24542354a544c82c4fc9b796f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/75656782fd05945b969b3aa96ca0da4bed56d2137b9d755ae32abe9eb39e215b1be0bf1bcd37e6779b8430810445343ee41ad42667dccac4f88f3a1c385b9129.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/29fb64d9095709c23cfe7070bee45423745e96ab3ec37b67988bdb768742198210b1b30d6f90f7f645602a9f564511a6d1d0b308f79e17443299e3e58e6c0e12.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/60a737d1353892b5a58f9d594fd489d436838fd851ec70170fa67b952bb4c4fdaa21abb7987bb08b348a1336b6d1ff47177b77b93cea99a5e75d1d6a255b5fcd.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/ec6c6dd38f87f97ffeaccf275d3ac31364f663968dbf37bed6c37a7bf95162167bb70c130b44eeef536630eec059d57a3c3754743e97b7f2a45d0bca5e3b12d8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/74e4f2077af77af73ec63a97c111b401df6c22a175b0eed844db1027fb33fca9e428baee06ac09b4e694487b105b0a2fedeed2c07352888c6eb9e1faa4f66f0f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/cde6a0209b56f4c161b49fb92ccba987220bf3ac1183c422ce73c56abe52ff47e83fcda07d8a7891ae791f2919eb09d67d7a12057a0a98a6e8e033475d0d70fc.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/5f58418684082c873f81d6de31e8a368c092d9477ac2a94eaf7782e8175980e02e1e470ffd5c9603f28388b33e6a8cc92cd3227f33fa9e363045c5f9b94d26b9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/4f325bd3e15b8118bf9a63e94476d7e807ed0ee4e57799a8b8a2d9d8faa3dbb9e55fd2072bfb0df08ba359e935d8b921fd11d0f0e11917ee25730015d22dc443.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/38da015ff086d1c50e595a2fbcadb4dea0e557b8524733eff65a4109465a439440b77196ad191f98e4cc07efcd89eebac28f71a8d5d05808ea99df248c5862f1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/bc11ac4f4b7a6078a455dd9fe9a6f6cd74d5f43ebd6e1d7646f384d015aa86644df73056720bd2f8954d2602174e5457a868d72c89ce85c53fa0bb3bedde54c4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/70f1964598b78612fe0b1f823765358c748c58ffd3f23c2b37516ee9b45f65d154c2481a474b6ec6a0efd0cac435bc48f3c12612d147b2b61a8b438d494ee33a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/35964467b7e66b91dda3b591c3734eb01629fcbf402132a19da7d75c3df7af9a2a0cfdd7af43b5be97745fe1227486b718de5fb8f529b6d272aa26d9e43db26a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/6ccb40a489f0660a1487d139cba92a8ec4b362faa057fb92e3b61df8551d57bf4cac40da539974a172dcc4f1ab5fdc0d4e4eda91679732e8659214c43be3cf0a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/d55cf57a7152acd7f872312fd66387cab4c27968eec104a24b42e54c0edf3dfd3d01be705158c69df3ac85ebf06123751ae9f8939811761df5753a2d668e7137.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/80d8b09e1d0ac2d2e288a9cbd01f9587496026a13443e67d57b1996040187eff4781d336fb78cbda5208db6e29d50a496984c25abc527b67fd6d1cab5b1c35b8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/59361c8fc11e34f80a9ca9b6289b30dd7f3df9d493ba176dc68835082a9d652e95aa49de9aa1c442201bf3e5ad8d06f2d2ec042c74cba46bdeea0586dc4a8643.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/bda099056c2a8f95f677433f2bf82e3623ea6c7cb2df7340ec928244b040a5d2b7379b2d74ab5497a28687290b5e4a92dffb3c9ac429673181d8963047324853.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/863fa422b1d8eb9bf1d0d8a98202321cb68048fce793762c9df161db5daaef0ef42da359cb8bc422c25516e08f36928662b250b2e0efb2bd46fa499854cec271.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/abb72ee434367bd5676f28a6acd9877805e73a94d32645627dd0c4198d26175fc65a4942850172bd35ea5cda4281b072ddbe4b5a89b3179fe61cf64b58802dcf.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/b12ef3284ffc648b8b1d3b77e4265d054e4cfaf421c7ae1a71f9b343beb904e8e1aa2d7802e9cf4a65079cd0363ee79957981c13a7a81dea57a386ef2fae8e4f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/a44053873586b62eba57fcd3779242109334ba5bc347fc3690cc8f2cc7f2c1a72b6b076a06f3a5efe13b4498e8afc2dee2dae286088359c8e8b1c7484b159f58.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/f8c6c5ad5bcea953f813e853139c62bc3f242bc00055c9bb989d54fdde44476563078bb32c4164e82ba26b76849e2651499c3f1842f75ebe54762b196f1253bb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/158c3c14a21538f27311665d3dc37c4aabe338f1a82a0d6feae0f9d9294e21b6cc16406f74d77d3f8f26837293e6c8741d4c4663bfa62c7b93ca7496bc428d9b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/d98a747a828dc3d72271b4d2b11465bb5fcc45c9a77c416f20f2f4299f5e3959f69378e72777be753b690b4dae77b8684e12d0db27dfa851e22335135d5cea54.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/def02d23092cc0d25ce1cb09d533d249644d06b12773d282c923c8572c2068124ed74bb5ed51832764fcc72bb0c52402e86f77ceeb708c050770ec71e7dd01e1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/a3cbfa8bc2af892ca91e8ef7e7f109119f2af12887b62c66f74ff891d97445c4ae5f726b1b3402acabe792f9790d16202085e0b7fb70ca41f6cf2cd7be47c6c0.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/6f9593193b2469f6620b07aee33de248f02ea86ee19f5bdc17e6c5aa464fb71a5123e7a061601498f5d2d68c90f9faa475266c6ff70d650548c6f30ff74b2b14.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/830fdc86aa25c5679cecff77ab4d414af640b8ca08098cab230fd75faa95f37720259d6a57a894b6a01a51dc8ccf41855bbbe39287c05b63630c6c5fbdba9a62.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/4c88e693bc0f3619c4ed434ea793f5919c67047b113a1b7f417af6c3a84c60e5abac3016beca5eb215edda64fb382b9e3cc6af85d10a1b5ead1636c754ceb25a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/5acc6d331798fd4101b76e94c6f0177d7fde2421530c4cf1ffbe3d49f66e6babc04976445a29104a585bdc1847611708a6cf5bb5f1e87fc9909713c569f7f2f7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/e0eb246eb642d1cdf80571bdc83f5774af7cb84c460212d16dde1e49d00c90c5ab793493a512b478cfdbc551e6c4129321474b52a55825bd8b8c47da8d85d5ea.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/8ea69aba0936d459dd580b3eea2c7933b9c20062772387a1e14dd8ba1fd208cca4fc0c28f0b7fdfd81d066ce8de49dfb5970d218f16309cda182f60c030e6916.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/652140e6d8e1a7f8d5f6570e9bf2960e6f4e39b27cf1d515e295004ee037e4df9e694f1f5f448b5b3e5d47936050a515939ed2071a094ed1adf5a19f40676b1c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/65914975dc3d7220a3456145739e41ae7eb8b6c74afb24eb23414929a41562445f3dfccd1cd651bb844053834c32532c7d2504548faf461f39a2347896268441.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/090190dc8a8a5293e16f17cd5cc4de601c1e5a01a4c67d39e4ad3bf95693a93de782005788de1b0f55edfac5bc3627bf74fbf2b2effcf981c81d16139a398712.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/49f540810e775ff5b66ab170cfbd0a256e618bac1d037d05c2148b1c477af097df32557deed8c73e7ed912c08a85a96ad669a99fedc2e8735f29d60b385e07fe.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/9732b106faf2db8b2552286423a331ecde7f600db8fb26cb685391fc21a64a0540092788563463c5d3f72bc30e3c05de6a2a507c52fadd4993ea0ccbb01c5b8b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/afc91bab93361e94078c3bca7eedf8986c8cb367326fe655cf6156071c4d268439f426c2d9766d128875e2eaed473065048227aaed076ff2b3d29050f9a4472d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/719ff0bca80b555185402e25011620cb54e5176350a590b3f32a42a05235550bda977365b7b06d57d3e55c55cee267d39e8b5f0f14bcb2f61ffd19615764f141.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/735a549c274b71a5ba594090284518ac3d3b051d54cc31e918a6fd0068e813f3c36e0376c7ec88dc54bfadfa37c261daef2d0961acc25cf2e6e8c2240ade0dda.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/d7828da7d560b01519342dc1abc91bb1052bd7f268fc4a2880c1f9a5b58f42fd297bb5db6c425187fc4618a171817d7200a0f91db783d7fde0f4ab59e9525739.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/cc40a81cd30185587f2e1cc6a3dd06e055e4588989afd1ef50c12e9dadf721f8de632fba8589c191073c138bb97eb3c43a3de52244c19aa0bd2939efc73f2e3d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/bdc2d2c7efa691fe7f111ff41295e5a45e84da884dfc50137e8f506203cde7e7b74c51616fa8c6245457ce88fe05a21d98fa3bd635d9fda3bf2fbf34a9610750.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/fad08137d57a29a8e3b37413aeac6013c6774ae57eb0b5fbe8471bded5cfe252ee455e1f23e906d0c372c3dcaa308be9809443ea24b08e88e69bf37ecf830481.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/f114e95348c1b63d5cd684fe95a879135f6ff29f6aa6196fc77d7f447b4b17c4c128d0be8d9bf759aebaf34e98682276b6d92ecb67ec530f4753e583c91b2ffe.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/1fd3c9350368c5d0f58c467b7be4c05472d6c21a8893892220df94282ea413b178bd653d2cd30066c3de439ca1be7a2c429cb6a9ebab4d24046aa9adf2fe2051.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/fc9c22f065a29fa9edfa017bfe828d358b5f5f3e172f2b7560dcf6262ed375d02d858ae09a6e8ec758f79d8728181394562366322b36900694d4f33942868708.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/e395885ae6ccb9ea0d0de3d86d7326c71b6c090ad630281bb08665ab9fa7e89d2a6119e1943f83a5ffd8e35a7d683d92d88f3d1e58deaf7ac84b01cd4896c341.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/82ca3c2c827921d2b90738b5e454c1f3a0003afa6c020ab2e3a270bf4a5316d28bfa83106bdd6622509dc427b7f0bbffbcfea2bed0852e67ac059b30d860e6d8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/005028f1770cc5685e9654a9df1f623b31c7f8fd3fac1dc8fa0fbdeaf37dd1486d25234c3abd4d8382fb3bf46b34cbf79038124d0740ac22a09457bc03e66a24.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/7f821b714c8d275b3e8d3bc214968eb09d8367cdd2a1640dfa68ad1c1300fc65ce3153a508e1b773bb43514065e50c63360455043d0eb61a8c22cd7f897f3d47.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/6b17512cf101ace29089f08a360555f6973275fc0831b64d987125060b04ccfc362411063ccdaf08a291ed931be6e8e4a5f4bfaa4461c544ba133af6b738494a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/370256e3440275be45e5446115fdfd88bab43c03ac07a3c5bd073c9f6cc676e6922fda754f695df63059d37ffcc1fdf4854de4b264225cfe4e687f264e1ae744.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/d1305c1dc70e04cf5ba003a173f5fbfaf6a3115dc4bcd883e0f27088e75fdbbc2a0921041cec4ad576b823e47ab353ab6de6a0a81ad4bcda1a8b2f98fdba75af.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/558638ad961d8807a7576e95dd4928f039f091c6e3bf7dbc33f8dfb6355362ec069d70e54562484d0c2e47b5f70362e2ad291f12de1309c491428ef740d68471.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/c74bc81d3592697a2cef074c04a80c170a34c56d0e611607ee99badbd784f8cc84b289dddb4005296d64d13dbf937a3b1298dc8793775b467a3ab3025cfacbab.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/5f0acc56f742d95fe676ec6004565f77451c43cdaab7eee503ffa14b22d513eb7232d9f1582d4ce0f4398993131be9eca1b5f0f645a5429dfd15999ddc75c1bb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/4c08f13a2676e7e5dee22d4935a92cc765ff65267b1ff537553a40dcaf5abd962240a55ee74935ad5ff9e6c3ad4b37f1413f76a79063b336ca1681096e467b76.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/e28fd9b0d7c61fdcd9c555a2286a8d9d5135c305a73fd2e8a6597ce58cbfa2c7972ba8f8cb56594ebdb41eb368fab3fd59fe9102fed38d691053e0be3e3ddfa2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/629ea1da3276acb98127665a0192e11e14de5534ce7a5ddcda9132f2f931ff47f97748ff5b6166c957f71e0028fd9f1b99305a850835545eb7c92a7454e9d84c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/6109a930ab69577090e23b6018d5d3b1edc8a664022165070e5249aa0729395ed94ef049a7c0aa3822e8332f9fd8b4aea9a9e0da326a4f3762c4fb614575bfe3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/11d41a374d20c71f6a6efd14845339509a6055a33043e6964ca9beb37900c67354f88ab7e0a43d0ec02039645fb303eb91d44f3a3a134a8ca68c5be4d7af901e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_19/train/d77606a9eca21447d4eae8f16fcea2771004a068cc49c93dfa82d6ef019df724c9ae6bbaafba1304c3c544ec1ff9289eb9bb3ce6aecae8ba29cba764ddeef69f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/8b95dc3a33e991a8537f24c9f1a18f79ba120c42a46fdf41e5a333bb9026fb1008c44ef18967354d962f9880a037783b1cb0dec8dc147256bd68994e78a88ca9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/3517d410dc94c9623f7a4f22e57a0716596de97c85d33e426d84343361ef4e0dfeb09e41b673db84a7abbda85200d56551415b27f1b86e51ffde1b8c75c78272.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/063b0d2724b861f476f1e736b64116725ca93c42b1479299c091210b63c95f461694e04f7d911cfe4490a863e15350d8265d20a906500bbfa27bef238538a62f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/52e329c51899c25d19241301a3707b16d16607d5658805c4980c3fd8f0bfc3079147e378a8465c654cd9ff3b06fba42992382c04c2c254a18efc52ce852fea0d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/34ec95de8ac0a2cd522ef58281537aa69cd67f3d86dc3660e4d27d80ad54b3dd28d6fc6cf650e0f023b430f9da5fdf15cd13dd01d52e7debcb09dffa0a05179d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/5d61267e4ec98fb0b7781ab788ae114942f94b89d8355154762bbb22330fca41b9b9819e9cca7b62c94774dfa2eac36d97fcd136f2c97826da4b477f95aa92bc.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/6cbe91cf7a12dbd3ca71cbe0a64baa3c6e40e3ae34e2bcf8deb7fb00db713ee27aea7029fe146d650d65596f8a9f6c976efd2218d15cc326328410caf3f2fd48.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/8dde3eedddf4d94f4c382ea6078f582deff34e39ae6d1e37e807d03a7e992e70837eca9ab3dfee43f01cd4b963cc7c2783c2ec7cf5010f00447f15f1b9edc121.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/c1885333398db34bd037d2755584656db1c02c99db3397222722a4fb4353e6e3eec32ff3f4738fb4d78740847647e7b39992c392531006179f9bbf0a61f64e42.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/d7e6d1911d06c2e223a920967fd60bec1e3c998d276cbddb68d3ffcaecbae7e7a8fc199c02adfd2f540c41e6ff7a38b455360819bcb4d1f51f87d3b237f6223c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/d8e2f87812849dd68e6e0ab5cda5bd2ff1e584450f5e5491ec9b3df4b4f40b305f82c4b93c0bd25887da26e572ddb9e868c34ac9f0ceeb61fa0862781297ddde.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/675a09efa1e5e1d8ac4f7feeca7e07d2b3b3e832ef64a50a7cd93237fd756c9efe7776ac9b0093119b36209319a4018c45e1ade88f95cc6a38f9b21d0917253a.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/19b9cbc84dfa26bacdc818f2b1a4a1905981c6f53d236a74c60009ca99d13bee8899c4075020b6e8d227df2b7c52ea0991f0687d8427d226a004fa9e97dd1d68.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/9ffd10df68f31ae43922807823a05e8efc20287545fa0e720c693f748ed2339383654939829502f1e3dd73c2132847e9d9c2644fb810d8b99beb3efa93cf31b9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/66a6bb231c6d5b4f94efc69a4560a202b84d5d7f10d2d8f850580ba55cc51a03f07ae04d00ba86eee6ab77bdc534fb6456d4939870d4d96e8bdbd3f62c491b53.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/59f71ae36fc167fb97af30f7a499ba3e070d3a5c320d479f8db369382a5e450e18494e46f2613d94e54723ecbeedc3f721ea070ba03f208df958fd89139be259.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/e7109b879815863329e2b5d7bc3fc13f70d8665e9a9a459c0c451e2c1d5588ce0c0d491761d78b973a21a0a3b344e7328c3ec8207f6f7855b33c0a92514579a1.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/45dd08947b645b9bd090336038ee1663d95dd96c8b078e6601ef3caab92e0932daa4596774789c306263558fc4980483827e0ff9a772d727061bc0e0f888c473.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/db3a6b060ff83729ceecce83f7923891f1d716bac2f0684fce14108908253a5903d5a396f05b138ae3721465ecf1d4b7138c116633de5f7d76af36e942d44972.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/05d956bca4d0d4b5bd715b4467700c39a34ec6c62e3df73316eab25d5306b5dc3cf5b353c57cd0c11c06ef0790aa9cb41d8a8a583730004c6b38cff221a1e0bc.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/cbe3486f10c4b0925a388097fc0041f693d16b9ce6d5098a6234bd026795a69acbedca7d27ce0adfad468befcb759876996d2a8359bd1549e59a6f45866b6bd7.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/9f7e0834b9f18b4cdbf2d914969f59af7b0d214831a669a314901f6af59fc4c3d113b07c60fcf630b0243967c1514d07e535cb88f372384d037bb2dbccde752e.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/0f7331567b744169f2c0f773ac366fc2449adbce74161bb9854ca5a0761ee4f40d696dd1dc242365bc0c13258047c3d1dee92eadac597a4a1255aa7033cab7d0.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/ab200a562351db66cff559f76c1cf74bdaef363c046595e495aaa4fd985af6d31f38fd0ef7356ee16be65717bda59e71f703a1fe7ec9f974fc50402c450793ce.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/6cce82a2d555f88ccdfed3ae699321e6634da70a81ad931331a4223309cd37e5b6cc3a187e067e2d59d8cd9b697b5d0cdf77b4e23829841493db091104db2e6d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/9a4394427f70f3c3073112e98ae120e2631db887a3baf5b426bfa758066763e39696b7808f812837f3b9b31d4db5f3dd4b07ccfd9d875557768f6ccad1d823b9.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/05da45dcba6acee73a3d236cf2414c4487dd659fd0ecc54e67fd8f8e49141d0c2d3de0e49b406eac79c3f5e418bd331b087ed5efc2b9cd3b31fc2faa0ed4fce0.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/7ec372bf32b308d13003ef34b8a4a6846a14957f40b3640336f44b4061eb19ca2e99c87b380155e7f59a7281a304ceaf30bef2747df6817756eb8bf25c9a3efd.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/49dde3a7dfd4a2c073cd64aea63613bea5e49fabc0fa9dee53e44de02740e3e30aa757a5f790077015a2ccad8bb99e52a1cdeb32ab90db28f8a4e2be468a45de.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/00551b38484e1878e05738fa85ebb42aabaed3a0b0cc0cce4b03328876e4ee078810b053df673265871dc44a5d8ddf7757bc48441b9ffa23eac3638cc6184b2c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/49f36508c9abdc249da4afc16caa336fd2c8deadedfde7336c18942db0c1b7e5bb0e788222548bfa20c1a1d9c7d1d684d641c982f9b5cd07852b8b0769c0fa1c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/23c2011836b9b78c6d871894c05b51d34667b41be7457d7f7f3f0aa454eaad5ce55368b23ea59a862e69fcb366b17970624a9110cdc464572e61f51dfeeeb7ec.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/15f2b16fd5fc213251e2953931904a5b5926cbb9255fed2d58faa591e6734d48f6851579efa1428b0cd34471b2c02f3b16c3691dd2d7bef142ca9043453d61aa.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/e66b22166c53ae09c8c8475f1e0d2bbc286f8d1c3333982dea03d98e2b813dc1ad46b59fa6f13ed49b3436b92d9229ca45d2fd87ee00f5acd8e0d6c132f4c3fa.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/e70ba3de5943853cb70346b3fb5254eff67d17206e3dec9ec22d0cf0628210006032eb11f6291e692af2372e0121d1a71bfdd2051c492103775dff2d767d484f.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/543979cd5f6b3745569eec0e8931b7559c5dd788214e02886b8fd914fa414befb573e486fab1c08453c6c1e3b982856fb50ce2ae73bcad3593dc1f4324873cab.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/30ff6d6ecb05f1be63dd8ec15213fe83464c85471f910045006b09d95ac0ed2fa7e829db3fe0bd559bd03539643cf1bedb90f314d5f61af6b05528a586e4b7d0.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/2de4cb1be279a2583ace6b0c5060f21805994acb4dca3daec6b448c51fd21663e7645a35367bfbea70cba81dc1c28952d9f43ccef344d25dcdba4d37a8e7a494.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/1872d4662885e10878738b7981d718630f0e7fad6184b3785a3c0c18497dbfed9565c9b2722a570fe24d2ce191d9948f592014d5432a5dd8ab242939ecca13a2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/d82f2d886dd990b5084bf733f9dfb26c14aea856662625a2ddc3f2aa0ff1613fd2db3084eef89a0a99f5aff0306984fea0a350b0711b828b3e58786bc129b719.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/b2ac301709fde652b52fdd597e526f193cc4554d280728d3e327184cc17874145f4f8f3213906364a8d17f9e77ba8e40143b9500633fec0ee011e1c76fcd6c10.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/f57f526bb22a73b0a20d75cdd6c4cac0aa825ec4ddc9088ac7c1bd366864a1b75ee12f08dc4b63863a922a5f2b29cb1c2b4cc3606578b20a369816a0475f7a82.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/6a54adcd6b9fcd1a065856047a019e898190835f6ce8ba3dc5184937ea05a0f4c35015122ae21c7f91d0ba7647f435baac9a7e6e248b2ccdd66216e7519d6330.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/8afbee062b5bd34a415b3b7069301323872c2b2397c493d02cb60daa8f571e9fb368f21801c2d83a4aa37e5b9c401427fc643d3c1241e4f2368818709b6d550d.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/4163294feb0e55eace1eb738eb91760886963c8ffd1db1821ea8eb75cf1efba63c481553a4014ba2a96cd8d279ac1258863c6cf34fc559051f5510a236c5f2f3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/f747b5c2193c537649c845ab9e9c2e639d0c4b83da9d5866679991a27c2432a7c12674865c415e81399c31429fd39d11d05d174455fda6e74489b0fea9e686d8.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/4daed2288cbb0f2de739a2d8fe6041bc3e983a14597fce4ab26356a74cb7874a85f821e3b8476fe407e72e554e5abfd126546dc89da92b2ab9285313ac6b0367.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/00096a34d03e6f5ca87926724182c61f4b8e28f7fa19b8f82d73b15575fa00fbb678fc66bc2ab5c9ff23d09d6c7293bd2e7355d2ba506789dd8aa17102900906.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/b795d67e32484de7f68b162cf5193f3a26d997a95b9f6c5891ffdd3b5dd024aaa91cf49f1aa0fd0329239de43c00ee43a7663aee9e8622a7edc05ba2f2341ab2.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/76c8e740a24d0001a414bfb3f1fc99a681d5046cfc1f6be2a64f34b4b9651cf1dc56b4c4f866d30837efe1563e3de0f37c0af8231c89f59d2b37658a3b033c4b.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/3a4a519be470900780b9dc09ad2affd64f348b2c418e634b144d38d45dd224a3960cc5caca9b91c8952ab5f4f311520c8805dfc3fe6e42defc9e90dab3a02636.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/437fcd8baacfb85af1529fde69a8cb481d0f8bc7533f752153eee00f81c4c17c7dae966efc4ee224af1af7d3ce9192b3b5c5e0a4234673ff6532af6a8c1de2c6.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/f621f5e86b3bfe37e3cb8ae36134083f6793732f72073fb98b72e5cc85953f11d367204bdfbf7b6caeed8b88d67171618afcf33d9dfc3f00a4cfc64f8fb1e33c.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/48d19d4178acefe03874186844e175403b92ae06d67a8617106d095f1982feefb1334a182e8a523948f1b8e0da4432e0bb6af1b953302a606ec4952d0906cca3.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/b47f9c8534220ca9ff9bf6e62335231346e0df2a71c9d1007a14b163ff7a23f1728cb9281d1ba99e1f1059351cce36f6c563182df3bc90c64879316229e916fb.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/834f12fd60f8eb4efe90e4310afbc2cbd889a725e4651e52124ec72ff411dedc9f5281e2a6caca4e8da9ad4b2981c4118f2d7ebf7ec69eaa0df3305670b0ec43.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/c1579020fc51720973dbc1fe3a632f72f5d5703ad94b07c98495156fcc78d64382a3f14acd5cdda9b3d122682d2fe4e3e36d5c43591aa7d4ca5285c8c14a9a74.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/db7ccaba82a73ee5017f1ba3046acde2c89d121816d1156d603003dcdfbbb16d5cb9646f5ddd24cf34a781e8599e437d144c33e26c793f239da8ed3bf85b34ee.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/52dbaf2b63c53e0d7a377dd054f576cf6a264928d2c2d75cee0d1f21b7f14ce512a1f833abe9dd836ebf2bde2308d3776879ce03ab7834af4913e58f927ef6d4.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/598b827b83e71d27d371074e8f6dad2bcbb2a60cc16666bdb317f25f667df6dd417c34d9a8156b8d12a755ba968aa414197f4afb4d797455767913cf8472d432.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/1c9670cdf08a42c18e22a21564dfb25f7b1e266811be745d95fdb6221e91efebe63107ae4c3bd9bec88cd97e34464d0736eefdaeb50e32b34b7f1ded6f572a10.mp3: \n",
      "Error loading /home/rag/experimental_trial/data/finetuning_dataset_large/speaker_91/train/89c98d2746bbf83fe34a78cf356426d02bee60f58a996924117c655fa10c9d49ce6e8ce8c978e1109e23ff93dd3e1d9b1518ca97d765ac6bdac31c5f67a0dde2.mp3: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import WhisperProcessor, WhisperModel, Trainer, TrainingArguments, TrainerCallback, WhisperConfig\n",
    "import math\n",
    "from datasets import load_metric\n",
    "from datetime import datetime\n",
    "\n",
    "class WhisperForSequenceClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(WhisperForSequenceClassification, self).__init__()\n",
    "        self.whisper = WhisperModel.from_pretrained(\"openai/whisper-large\")\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, input_values, labels=None):\n",
    "        outputs = self.whisper(input_values).last_hidden_state\n",
    "        pooled_output = outputs.mean(dim=1)  # Mean Pooling über die Zeitdimension\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "# Initialize the processor and model for Whisper\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Define the custom dataset class using pandas\n",
    "class LocalAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, subset):\n",
    "        self.processor = processor\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data['subset'] == subset]\n",
    "        self.speaker_ids = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "        self.data['label'] = self.data['label'].map(self.speaker_ids)\n",
    "        \n",
    "        print(f\"Loaded {len(self.speaker_ids)} speakers: {self.speaker_ids}\")\n",
    "        print(f\"Total files in {subset}: {len(self.data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            audio = librosa.to_mono(audio)\n",
    "            audio = self._pad_or_truncate(audio, max_length=16000)\n",
    "            input_values = self.processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_values.squeeze(0)\n",
    "            return {\"input_values\": input_values, \"labels\": label}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\", file=sys.stderr)\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "    def _pad_or_truncate(self, audio, max_length):\n",
    "        if len(audio) < max_length:\n",
    "            pad_size = max_length - len(audio)\n",
    "            audio = np.pad(audio, (0, pad_size), 'constant', constant_values=(0, 0))\n",
    "        else:\n",
    "            audio = audio[:max_length]\n",
    "        return audio\n",
    "\n",
    "# Paths to dataset CSV file\n",
    "csv_file = 'dataset_large.csv'\n",
    "train_dataset = LocalAudioDataset(csv_file, processor, 'train')\n",
    "validate_dataset = LocalAudioDataset(csv_file, processor, 'validate')\n",
    "test_dataset = LocalAudioDataset(csv_file, processor, 'test')\n",
    "\n",
    "num_speakers = len(train_dataset.speaker_ids)\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=num_speakers)\n",
    "model = WhisperForSequenceClassification(config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "\n",
    "def validate_labels(dataset):\n",
    "    for item in dataset:\n",
    "        label = item['labels']\n",
    "        if label >= num_speakers or label < 0:\n",
    "            print(f\"Invalid label {label} for item: {item}\")\n",
    "            raise ValueError(f\"Invalid label {label} found in dataset.\")\n",
    "    print(\"All labels are valid.\")\n",
    "\n",
    "validate_labels(train_dataset)\n",
    "validate_labels(validate_dataset)\n",
    "validate_labels(test_dataset)\n",
    "\n",
    "batch_size = 8\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "logging_steps = steps_per_epoch // 5\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "log_dir = \"/home/rag/experimental_trial/results/training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = os.path.join(log_dir, f\"training_log_100_epochs_5_layer{timestamp}.csv\")\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"Timestamp,Step,Training Loss,Validation Loss,Accuracy\\n\")\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                step = state.global_step\n",
    "                training_loss = logs.get(\"loss\", \"\")\n",
    "                validation_loss = logs.get(\"eval_loss\", \"\")\n",
    "                accuracy = logs.get(\"eval_accuracy\", \"\")\n",
    "                f.write(f\"{timestamp},{step},{training_loss},{validation_loss},{accuracy}\\n\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=100, early_stopping_threshold=0.0):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric = kwargs.get(\"metrics\", {}).get(\"eval_loss\")\n",
    "        if metric is None:\n",
    "            return\n",
    "        \n",
    "        if self.best_metric is None or metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = metric\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.early_stopping_patience:\n",
    "            print(f\"Early stopping at step {state.global_step}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    group_by_length=True,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=100,\n",
    "    save_steps=logging_steps,\n",
    "    eval_steps=eval_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=5e-6,\n",
    "    save_total_limit=2,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,  # lower eval_loss is better\n",
    "    save_strategy=\"steps\"  # or \"epoch\" if you prefer to save every epoch\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validate_dataset,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[SaveMetricsCallback(), EarlyStoppingCallback()]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test set evaluation metrics: {metrics}\")\n",
    "print(\"Training and evaluation completed successfully!\")\n",
    "\n",
    "best_model_dir = \"./results/best_model_100_epochs_5_layer\"\n",
    "os.makedirs(best_model_dir, exist_ok=True)\n",
    "\n",
    "trainer.save_model(best_model_dir)\n",
    "processor.save_pretrained(best_model_dir)\n",
    "\n",
    "print(f\"Best model saved to {best_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparam tuning for whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2902070393.py, line 269)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 269\u001b[0;36m\u001b[0m\n\u001b[0;31m    nicht dieses model sondern das undere laufen lassen\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback, WhisperConfig, WhisperModel, WhisperProcessor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datasets import load_metric\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up logging for Optuna\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Load the processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Define the custom dataset class\n",
    "class LocalAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, subset, noise_factor=0.0, max_speakers=50):\n",
    "        self.processor = processor\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data['subset'] == subset]\n",
    "        \n",
    "        # Limit the number of speakers to max_speakers\n",
    "        speaker_counts = self.data['label'].value_counts()\n",
    "        top_speakers = speaker_counts.nlargest(max_speakers).index\n",
    "        self.data = self.data[self.data['label'].isin(top_speakers)]\n",
    "        \n",
    "        self.speaker_ids = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "        self.data['label'] = self.data['label'].map(self.speaker_ids)\n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "        print(f\"Loaded {len(self.speaker_ids)} speakers: {self.speaker_ids}\")\n",
    "        print(f\"Total files in {subset}: {len(self.data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            audio = librosa.to_mono(audio)\n",
    "            # Use the processor to extract features\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs.input_features.squeeze(0)\n",
    "            return {\"input_values\": input_values, \"labels\": label}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\", file=sys.stderr)\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# Paths to dataset CSV file\n",
    "csv_file = 'dataset_large.csv'\n",
    "train_dataset = LocalAudioDataset(csv_file, processor, 'train', noise_factor=0, max_speakers=111)\n",
    "validate_dataset = LocalAudioDataset(csv_file, processor, 'validate', max_speakers=111)\n",
    "test_dataset = LocalAudioDataset(csv_file, processor, 'test', max_speakers=111)\n",
    "\n",
    "num_speakers = len(train_dataset.speaker_ids)\n",
    "print(f\"Number of unique speakers: {num_speakers}\")\n",
    "\n",
    "print(f\"Labels in train dataset: {train_dataset.data['label'].tolist()}\")\n",
    "print(f\"Labels in test dataset: {test_dataset.data['label'].tolist()}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def validate_labels(dataset):\n",
    "    for item in dataset:\n",
    "        label = item['labels']\n",
    "        if label >= num_speakers or label < 0:\n",
    "            print(f\"Invalid label {label} for item: {item}\")\n",
    "            raise ValueError(f\"Invalid label {label} found in dataset.\")\n",
    "    print(\"All labels are valid.\")\n",
    "\n",
    "batch_size = 2\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "logging_steps = steps_per_epoch // 5\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "log_dir = \"/home/rag/experimental_trial/results/training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = os.path.join(log_dir, f\"training_log_versuch2_2layer{timestamp}.csv\")\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"Timestamp,Step,Training Loss,Validation Loss,Accuracy\\n\")\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                step = state.global_step\n",
    "                training_loss = logs.get(\"loss\", \"\")\n",
    "                validation_loss = logs.get(\"eval_loss\", \"\")\n",
    "                accuracy = logs.get(\"eval_accuracy\", \"\")\n",
    "                f.write(f\"{timestamp},{step},{training_loss},{validation_loss},{accuracy}\\n\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=100, early_stopping_threshold=0.0):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric = kwargs.get(\"metrics\", {}).get(\"eval_loss\")\n",
    "        if metric is None:\n",
    "            return\n",
    "        \n",
    "        if self.best_metric is None or metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = metric\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.early_stopping_patience:\n",
    "            print(f\"Early stopping at step {state.global_step}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "# Custom classification head with mean pooling\n",
    "class CustomWhisperForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.whisper = WhisperModel(config)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.hidden_size = config.d_model\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        # Pass input through Whisper encoder\n",
    "        encoder_outputs = self.whisper.encoder(input_values)\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled_output = self.pooling(hidden_states.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Ensure the pooled output has the correct shape\n",
    "        if pooled_output.dim() == 1:\n",
    "            pooled_output = pooled_output.unsqueeze(0)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "# Custom data collator for Whisper\n",
    "class DataCollatorForWhisper:\n",
    "    def __call__(self, features):\n",
    "        input_values = torch.stack([f[\"input_values\"] for f in features])\n",
    "        labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "        return {\"input_values\": input_values, \"labels\": labels}\n",
    "\n",
    "# Extend the Trainer class\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_loss_model_dir = \"./results/best_model_loss_2layer_versuch2\"\n",
    "        self.best_accuracy_model_dir = \"./results/best_model_accuracy_versuch2\"\n",
    "        os.makedirs(self.best_loss_model_dir, exist_ok=True)\n",
    "        os.makedirs(self.best_accuracy_model_dir, exist_ok=True)\n",
    "        self.best_eval_loss = float(\"inf\")\n",
    "        self.best_eval_accuracy = 0.0\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        current_eval_loss = eval_metrics[\"eval_loss\"]\n",
    "        current_eval_accuracy = eval_metrics[\"eval_accuracy\"]\n",
    "        \n",
    "        if current_eval_loss < self.best_eval_loss:\n",
    "            self.best_eval_loss = current_eval_loss\n",
    "            self.save_model(self.best_loss_model_dir)\n",
    "            print(f\"Saved best model according to eval_loss: {self.best_eval_loss}\")\n",
    "\n",
    "        if current_eval_accuracy > self.best_eval_accuracy:\n",
    "            self.best_eval_accuracy = current_eval_accuracy\n",
    "            self.save_model(self.best_accuracy_model_dir)\n",
    "            print(f\"Saved best model according to eval_accuracy: {self.best_eval_accuracy}\")\n",
    "\n",
    "        return eval_metrics\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        input_values = inputs.get(\"input_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(input_values=input_values, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest the number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 24)\n",
    "    \n",
    "    # Load the model configuration with the suggested number of layers\n",
    "    config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=num_speakers)\n",
    "    config.num_hidden_layers = num_layers\n",
    "    model = CustomWhisperForSequenceClassification(config)\n",
    "    \n",
    "    # Apply the number of hidden layers correctly\n",
    "    model.whisper.encoder.layers = torch.nn.ModuleList(model.whisper.encoder.layers[:num_layers])\n",
    "    \n",
    "    # Transfer the model to the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        group_by_length=False,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=3,\n",
    "        save_steps=logging_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        learning_rate=1e-5,\n",
    "        save_total_limit=2,\n",
    "        no_cuda=False,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,  # lower eval_loss is better\n",
    "        save_strategy=\"steps\"  # or \"epoch\" if you prefer to save every epoch\n",
    "    )\n",
    "    \n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validate_dataset,\n",
    "        data_collator=DataCollatorForWhisper(),\n",
    "        tokenizer=processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[SaveMetricsCallback(), EarlyStoppingCallback(early_stopping_patience=50)]\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate(validate_dataset)\n",
    "    return metrics['eval_loss']\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=12)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "    \n",
    "nicht dieses model sondern das undere laufen lassen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dieses optuna optimier skript ist das richtige\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in train: 8880\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in validate: 1110\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in test: 1110\n",
      "Number of unique speakers: 111\n",
      "Labels in train dataset: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110]\n",
      "Labels in test dataset: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110]\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_822349/1595732710.py:104: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = load_metric(\"accuracy\")\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[I 2024-06-20 22:42:21,885] A new study created in memory with name: no-name-cced385d-d227-4b3f-8daa-6538206ca835\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 4:11:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.921500</td>\n",
       "      <td>4.795257</td>\n",
       "      <td>0.017117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.571100</td>\n",
       "      <td>4.397316</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.316300</td>\n",
       "      <td>4.281329</td>\n",
       "      <td>0.030631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.169000</td>\n",
       "      <td>4.050462</td>\n",
       "      <td>0.039640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.900100</td>\n",
       "      <td>3.756890</td>\n",
       "      <td>0.058559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.651300</td>\n",
       "      <td>3.500886</td>\n",
       "      <td>0.111712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.451800</td>\n",
       "      <td>3.270682</td>\n",
       "      <td>0.132432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.281300</td>\n",
       "      <td>3.143292</td>\n",
       "      <td>0.157658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.155400</td>\n",
       "      <td>2.969024</td>\n",
       "      <td>0.181081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>3.010100</td>\n",
       "      <td>2.893345</td>\n",
       "      <td>0.206306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.864600</td>\n",
       "      <td>2.850201</td>\n",
       "      <td>0.200901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.801600</td>\n",
       "      <td>2.724889</td>\n",
       "      <td>0.251351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.705200</td>\n",
       "      <td>2.659876</td>\n",
       "      <td>0.274775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.641700</td>\n",
       "      <td>2.619519</td>\n",
       "      <td>0.300901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.585100</td>\n",
       "      <td>2.582861</td>\n",
       "      <td>0.309009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.795257091522217\n",
      "Saved best model according to eval_accuracy: 0.017117117117117116\n",
      "Saved best model according to eval_loss: 4.397315979003906\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.281329154968262\n",
      "Saved best model according to eval_accuracy: 0.03063063063063063\n",
      "Saved best model according to eval_loss: 4.050461769104004\n",
      "Saved best model according to eval_accuracy: 0.03963963963963964\n",
      "Saved best model according to eval_loss: 3.756890058517456\n",
      "Saved best model according to eval_accuracy: 0.05855855855855856\n",
      "Saved best model according to eval_loss: 3.5008862018585205\n",
      "Saved best model according to eval_accuracy: 0.11171171171171171\n",
      "Saved best model according to eval_loss: 3.2706823348999023\n",
      "Saved best model according to eval_accuracy: 0.13243243243243244\n",
      "Saved best model according to eval_loss: 3.143291711807251\n",
      "Saved best model according to eval_accuracy: 0.15765765765765766\n",
      "Saved best model according to eval_loss: 2.9690239429473877\n",
      "Saved best model according to eval_accuracy: 0.1810810810810811\n",
      "Saved best model according to eval_loss: 2.8933448791503906\n",
      "Saved best model according to eval_accuracy: 0.2063063063063063\n",
      "Saved best model according to eval_loss: 2.850201368331909\n",
      "Saved best model according to eval_loss: 2.724889039993286\n",
      "Saved best model according to eval_accuracy: 0.25135135135135134\n",
      "Saved best model according to eval_loss: 2.6598756313323975\n",
      "Saved best model according to eval_accuracy: 0.2747747747747748\n",
      "Saved best model according to eval_loss: 2.619518995285034\n",
      "Saved best model according to eval_accuracy: 0.3009009009009009\n",
      "Saved best model according to eval_loss: 2.5828609466552734\n",
      "Saved best model according to eval_accuracy: 0.309009009009009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 02:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 02:57:07,878] Trial 0 finished with value: 2.5828609466552734 and parameters: {'num_layers': 16}. Best is trial 0 with value: 2.5828609466552734.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 5:35:41, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.926100</td>\n",
       "      <td>4.800497</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.574800</td>\n",
       "      <td>4.387306</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.298300</td>\n",
       "      <td>4.243195</td>\n",
       "      <td>0.028829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.115900</td>\n",
       "      <td>3.991580</td>\n",
       "      <td>0.051351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.830500</td>\n",
       "      <td>3.685561</td>\n",
       "      <td>0.087387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.553100</td>\n",
       "      <td>3.389331</td>\n",
       "      <td>0.114414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.332300</td>\n",
       "      <td>3.185437</td>\n",
       "      <td>0.146847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.149700</td>\n",
       "      <td>3.015546</td>\n",
       "      <td>0.163063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.046000</td>\n",
       "      <td>2.885855</td>\n",
       "      <td>0.213514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.921400</td>\n",
       "      <td>2.809806</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.801900</td>\n",
       "      <td>2.781612</td>\n",
       "      <td>0.238739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.734800</td>\n",
       "      <td>2.651456</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.644300</td>\n",
       "      <td>2.603992</td>\n",
       "      <td>0.302703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.603100</td>\n",
       "      <td>2.560126</td>\n",
       "      <td>0.326126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.524400</td>\n",
       "      <td>2.534304</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.800497055053711\n",
      "Saved best model according to eval_accuracy: 0.013513513513513514\n",
      "Saved best model according to eval_loss: 4.387305736541748\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.243194580078125\n",
      "Saved best model according to eval_accuracy: 0.02882882882882883\n",
      "Saved best model according to eval_loss: 3.991579532623291\n",
      "Saved best model according to eval_accuracy: 0.051351351351351354\n",
      "Saved best model according to eval_loss: 3.685560941696167\n",
      "Saved best model according to eval_accuracy: 0.08738738738738738\n",
      "Saved best model according to eval_loss: 3.389331340789795\n",
      "Saved best model according to eval_accuracy: 0.11441441441441441\n",
      "Saved best model according to eval_loss: 3.185436964035034\n",
      "Saved best model according to eval_accuracy: 0.14684684684684685\n",
      "Saved best model according to eval_loss: 3.0155463218688965\n",
      "Saved best model according to eval_accuracy: 0.16306306306306306\n",
      "Saved best model according to eval_loss: 2.885855197906494\n",
      "Saved best model according to eval_accuracy: 0.21351351351351353\n",
      "Saved best model according to eval_loss: 2.8098058700561523\n",
      "Saved best model according to eval_accuracy: 0.23333333333333334\n",
      "Saved best model according to eval_loss: 2.781611680984497\n",
      "Saved best model according to eval_accuracy: 0.23873873873873874\n",
      "Saved best model according to eval_loss: 2.651456117630005\n",
      "Saved best model according to eval_accuracy: 0.2702702702702703\n",
      "Saved best model according to eval_loss: 2.603991985321045\n",
      "Saved best model according to eval_accuracy: 0.3027027027027027\n",
      "Saved best model according to eval_loss: 2.560126304626465\n",
      "Saved best model according to eval_accuracy: 0.3261261261261261\n",
      "Saved best model according to eval_loss: 2.534303665161133\n",
      "Saved best model according to eval_accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 03:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 08:36:40,952] Trial 1 finished with value: 2.534303665161133 and parameters: {'num_layers': 22}. Best is trial 1 with value: 2.534303665161133.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 4:51:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.921300</td>\n",
       "      <td>4.799598</td>\n",
       "      <td>0.009009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.589400</td>\n",
       "      <td>4.391996</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.304500</td>\n",
       "      <td>4.280290</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.138200</td>\n",
       "      <td>4.032524</td>\n",
       "      <td>0.043243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.919500</td>\n",
       "      <td>3.789524</td>\n",
       "      <td>0.056757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.674700</td>\n",
       "      <td>3.469192</td>\n",
       "      <td>0.110811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.435500</td>\n",
       "      <td>3.277332</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.240900</td>\n",
       "      <td>3.085491</td>\n",
       "      <td>0.165766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.103400</td>\n",
       "      <td>2.933263</td>\n",
       "      <td>0.213514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.964500</td>\n",
       "      <td>2.834480</td>\n",
       "      <td>0.222523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>2.800629</td>\n",
       "      <td>0.211712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.749800</td>\n",
       "      <td>2.677934</td>\n",
       "      <td>0.254054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.667700</td>\n",
       "      <td>2.616794</td>\n",
       "      <td>0.301802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.601600</td>\n",
       "      <td>2.564171</td>\n",
       "      <td>0.312613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.540800</td>\n",
       "      <td>2.538898</td>\n",
       "      <td>0.320721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.79959774017334\n",
      "Saved best model according to eval_accuracy: 0.009009009009009009\n",
      "Saved best model according to eval_loss: 4.391996383666992\n",
      "Saved best model according to eval_accuracy: 0.021621621621621623\n",
      "Saved best model according to eval_loss: 4.280289649963379\n",
      "Saved best model according to eval_accuracy: 0.025225225225225224\n",
      "Saved best model according to eval_loss: 4.032524108886719\n",
      "Saved best model according to eval_accuracy: 0.043243243243243246\n",
      "Saved best model according to eval_loss: 3.7895243167877197\n",
      "Saved best model according to eval_accuracy: 0.05675675675675676\n",
      "Saved best model according to eval_loss: 3.4691920280456543\n",
      "Saved best model according to eval_accuracy: 0.11081081081081082\n",
      "Saved best model according to eval_loss: 3.277332305908203\n",
      "Saved best model according to eval_accuracy: 0.13333333333333333\n",
      "Saved best model according to eval_loss: 3.085491418838501\n",
      "Saved best model according to eval_accuracy: 0.16576576576576577\n",
      "Saved best model according to eval_loss: 2.933262586593628\n",
      "Saved best model according to eval_accuracy: 0.21351351351351353\n",
      "Saved best model according to eval_loss: 2.834480047225952\n",
      "Saved best model according to eval_accuracy: 0.22252252252252253\n",
      "Saved best model according to eval_loss: 2.8006293773651123\n",
      "Saved best model according to eval_loss: 2.677934169769287\n",
      "Saved best model according to eval_accuracy: 0.25405405405405407\n",
      "Saved best model according to eval_loss: 2.6167943477630615\n",
      "Saved best model according to eval_accuracy: 0.30180180180180183\n",
      "Saved best model according to eval_loss: 2.5641705989837646\n",
      "Saved best model according to eval_accuracy: 0.31261261261261264\n",
      "Saved best model according to eval_loss: 2.538898229598999\n",
      "Saved best model according to eval_accuracy: 0.3207207207207207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 03:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 13:32:02,344] Trial 2 finished with value: 2.538898229598999 and parameters: {'num_layers': 19}. Best is trial 1 with value: 2.534303665161133.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 1:15:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>4.581317</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.434400</td>\n",
       "      <td>4.344041</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.287000</td>\n",
       "      <td>4.241272</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.153000</td>\n",
       "      <td>4.057652</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.804700</td>\n",
       "      <td>3.586735</td>\n",
       "      <td>0.091892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.440300</td>\n",
       "      <td>3.244352</td>\n",
       "      <td>0.163063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.178800</td>\n",
       "      <td>3.035362</td>\n",
       "      <td>0.177477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>2.991600</td>\n",
       "      <td>2.838237</td>\n",
       "      <td>0.241441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>2.855000</td>\n",
       "      <td>2.724710</td>\n",
       "      <td>0.272072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.714500</td>\n",
       "      <td>2.609525</td>\n",
       "      <td>0.303604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.562300</td>\n",
       "      <td>2.581823</td>\n",
       "      <td>0.290991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.503300</td>\n",
       "      <td>2.453549</td>\n",
       "      <td>0.331532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.406100</td>\n",
       "      <td>2.384757</td>\n",
       "      <td>0.354955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.367700</td>\n",
       "      <td>2.346510</td>\n",
       "      <td>0.381081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.307800</td>\n",
       "      <td>2.327127</td>\n",
       "      <td>0.386486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.581316947937012\n",
      "Saved best model according to eval_accuracy: 0.021621621621621623\n",
      "Saved best model according to eval_loss: 4.344041347503662\n",
      "Saved best model according to eval_accuracy: 0.025225225225225224\n",
      "Saved best model according to eval_loss: 4.24127197265625\n",
      "Saved best model according to eval_accuracy: 0.03423423423423423\n",
      "Saved best model according to eval_loss: 4.057651996612549\n",
      "Saved best model according to eval_accuracy: 0.04054054054054054\n",
      "Saved best model according to eval_loss: 3.5867345333099365\n",
      "Saved best model according to eval_accuracy: 0.0918918918918919\n",
      "Saved best model according to eval_loss: 3.244352102279663\n",
      "Saved best model according to eval_accuracy: 0.16306306306306306\n",
      "Saved best model according to eval_loss: 3.035362482070923\n",
      "Saved best model according to eval_accuracy: 0.17747747747747747\n",
      "Saved best model according to eval_loss: 2.8382370471954346\n",
      "Saved best model according to eval_accuracy: 0.24144144144144145\n",
      "Saved best model according to eval_loss: 2.724710464477539\n",
      "Saved best model according to eval_accuracy: 0.27207207207207207\n",
      "Saved best model according to eval_loss: 2.609524965286255\n",
      "Saved best model according to eval_accuracy: 0.3036036036036036\n",
      "Saved best model according to eval_loss: 2.581822633743286\n",
      "Saved best model according to eval_loss: 2.453549385070801\n",
      "Saved best model according to eval_accuracy: 0.33153153153153153\n",
      "Saved best model according to eval_loss: 2.3847572803497314\n",
      "Saved best model according to eval_accuracy: 0.35495495495495494\n",
      "Saved best model according to eval_loss: 2.346510410308838\n",
      "Saved best model according to eval_accuracy: 0.3810810810810811\n",
      "Saved best model according to eval_loss: 2.32712721824646\n",
      "Saved best model according to eval_accuracy: 0.3864864864864865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 00:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 14:48:57,848] Trial 3 finished with value: 2.32712721824646 and parameters: {'num_layers': 4}. Best is trial 3 with value: 2.32712721824646.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 4:07:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.923000</td>\n",
       "      <td>4.772852</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.540600</td>\n",
       "      <td>4.373076</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.305400</td>\n",
       "      <td>4.263580</td>\n",
       "      <td>0.032432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.152600</td>\n",
       "      <td>4.046790</td>\n",
       "      <td>0.042342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.926300</td>\n",
       "      <td>3.792199</td>\n",
       "      <td>0.057658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.659100</td>\n",
       "      <td>3.460390</td>\n",
       "      <td>0.126126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.390500</td>\n",
       "      <td>3.278624</td>\n",
       "      <td>0.127027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.176700</td>\n",
       "      <td>3.043748</td>\n",
       "      <td>0.172973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.058300</td>\n",
       "      <td>2.885319</td>\n",
       "      <td>0.223423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.928200</td>\n",
       "      <td>2.819576</td>\n",
       "      <td>0.225225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.796200</td>\n",
       "      <td>2.771602</td>\n",
       "      <td>0.237838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.725100</td>\n",
       "      <td>2.662514</td>\n",
       "      <td>0.255856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.653400</td>\n",
       "      <td>2.594802</td>\n",
       "      <td>0.293694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.590800</td>\n",
       "      <td>2.551847</td>\n",
       "      <td>0.306306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.518600</td>\n",
       "      <td>2.526243</td>\n",
       "      <td>0.312613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.772852420806885\n",
      "Saved best model according to eval_accuracy: 0.013513513513513514\n",
      "Saved best model according to eval_loss: 4.37307596206665\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.263580322265625\n",
      "Saved best model according to eval_accuracy: 0.032432432432432434\n",
      "Saved best model according to eval_loss: 4.04679012298584\n",
      "Saved best model according to eval_accuracy: 0.04234234234234234\n",
      "Saved best model according to eval_loss: 3.792198896408081\n",
      "Saved best model according to eval_accuracy: 0.05765765765765766\n",
      "Saved best model according to eval_loss: 3.460390329360962\n",
      "Saved best model according to eval_accuracy: 0.12612612612612611\n",
      "Saved best model according to eval_loss: 3.2786242961883545\n",
      "Saved best model according to eval_accuracy: 0.12702702702702703\n",
      "Saved best model according to eval_loss: 3.043747901916504\n",
      "Saved best model according to eval_accuracy: 0.17297297297297298\n",
      "Saved best model according to eval_loss: 2.8853185176849365\n",
      "Saved best model according to eval_accuracy: 0.22342342342342342\n",
      "Saved best model according to eval_loss: 2.8195760250091553\n",
      "Saved best model according to eval_accuracy: 0.22522522522522523\n",
      "Saved best model according to eval_loss: 2.771601915359497\n",
      "Saved best model according to eval_accuracy: 0.23783783783783785\n",
      "Saved best model according to eval_loss: 2.6625137329101562\n",
      "Saved best model according to eval_accuracy: 0.25585585585585585\n",
      "Saved best model according to eval_loss: 2.594801902770996\n",
      "Saved best model according to eval_accuracy: 0.2936936936936937\n",
      "Saved best model according to eval_loss: 2.551847457885742\n",
      "Saved best model according to eval_accuracy: 0.3063063063063063\n",
      "Saved best model according to eval_loss: 2.526242733001709\n",
      "Saved best model according to eval_accuracy: 0.31261261261261264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 02:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-21 18:59:01,174] Trial 4 finished with value: 2.526242733001709 and parameters: {'num_layers': 16}. Best is trial 3 with value: 2.32712721824646.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 2.526242733001709\n",
      "  Params: \n",
      "    num_layers: 16\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback, WhisperConfig, WhisperModel, WhisperProcessor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datasets import load_metric\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up logging for Optuna\n",
    "log_dir = \"/home/rag/experimental_trial/results/training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = os.path.join(log_dir, f\"training_log_optuna_optim_whisper{timestamp}.csv\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Add file handler to logger\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Redirect Optuna logging to the file\n",
    "optuna_logger = logging.getLogger(\"optuna\")\n",
    "optuna_logger.addHandler(file_handler)\n",
    "\n",
    "# Load the processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Define the custom dataset class\n",
    "class LocalAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, subset, noise_factor=0.0, max_speakers=50):\n",
    "        self.processor = processor\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data['subset'] == subset]\n",
    "        \n",
    "        # Limit the number of speakers to max_speakers\n",
    "        speaker_counts = self.data['label'].value_counts()\n",
    "        top_speakers = speaker_counts.nlargest(max_speakers).index\n",
    "        self.data = self.data[self.data['label'].isin(top_speakers)]\n",
    "        \n",
    "        self.speaker_ids = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "        self.data['label'] = self.data['label'].map(self.speaker_ids)\n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "        print(f\"Loaded {len(self.speaker_ids)} speakers: {self.speaker_ids}\")\n",
    "        print(f\"Total files in {subset}: {len(self.data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            audio = librosa.to_mono(audio)\n",
    "            # Use the processor to extract features\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs.input_features.squeeze(0)\n",
    "            return {\"input_values\": input_values, \"labels\": label}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\", file=sys.stderr)\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# Paths to dataset CSV file\n",
    "csv_file = 'dataset_large.csv'\n",
    "train_dataset = LocalAudioDataset(csv_file, processor, 'train', noise_factor=0, max_speakers=111)\n",
    "validate_dataset = LocalAudioDataset(csv_file, processor, 'validate', max_speakers=111)\n",
    "test_dataset = LocalAudioDataset(csv_file, processor, 'test', max_speakers=111)\n",
    "\n",
    "num_speakers = len(train_dataset.speaker_ids)\n",
    "print(f\"Number of unique speakers: {num_speakers}\")\n",
    "\n",
    "print(f\"Labels in train dataset: {train_dataset.data['label'].tolist()}\")\n",
    "print(f\"Labels in test dataset: {test_dataset.data['label'].tolist()}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def validate_labels(dataset):\n",
    "    for item in dataset:\n",
    "        label = item['labels']\n",
    "        if label >= num_speakers or label < 0:\n",
    "            print(f\"Invalid label {label} for item: {item}\")\n",
    "            raise ValueError(f\"Invalid label {label} found in dataset.\")\n",
    "    print(\"All labels are valid.\")\n",
    "\n",
    "batch_size = 2\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "logging_steps = steps_per_epoch // 5\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                step = state.global_step\n",
    "                training_loss = logs.get(\"loss\", \"\")\n",
    "                validation_loss = logs.get(\"eval_loss\", \"\")\n",
    "                accuracy = logs.get(\"eval_accuracy\", \"\")\n",
    "                f.write(f\"{timestamp},{step},{training_loss},{validation_loss},{accuracy}\\n\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=100, early_stopping_threshold=0.0):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric = kwargs.get(\"metrics\", {}).get(\"eval_loss\")\n",
    "        if metric is None:\n",
    "            return\n",
    "        \n",
    "        if self.best_metric is None or metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = metric\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.early_stopping_patience:\n",
    "            print(f\"Early stopping at step {state.global_step}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "# Custom classification head with mean pooling\n",
    "class CustomWhisperForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.whisper = WhisperModel(config)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.hidden_size = config.d_model\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        # Pass input through Whisper encoder\n",
    "        encoder_outputs = self.whisper.encoder(input_values)\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled_output = self.pooling(hidden_states.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Ensure the pooled output has the correct shape\n",
    "        if pooled_output.dim() == 1:\n",
    "            pooled_output = pooled_output.unsqueeze(0)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "# Custom data collator for Whisper\n",
    "class DataCollatorForWhisper:\n",
    "    def __call__(self, features):\n",
    "        input_values = torch.stack([f[\"input_values\"] for f in features])\n",
    "        labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "        return {\"input_values\": input_values, \"labels\": labels}\n",
    "\n",
    "# Extend the Trainer class\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_loss_model_dir = \"./results/best_model_loss_2layer_versuch2\"\n",
    "        self.best_accuracy_model_dir = \"./results/best_model_accuracy_versuch2\"\n",
    "        os.makedirs(self.best_loss_model_dir, exist_ok=True)\n",
    "        os.makedirs(self.best_accuracy_model_dir, exist_ok=True)\n",
    "        self.best_eval_loss = float(\"inf\")\n",
    "        self.best_eval_accuracy = 0.0\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        current_eval_loss = eval_metrics[\"eval_loss\"]\n",
    "        current_eval_accuracy = eval_metrics[\"eval_accuracy\"]\n",
    "        \n",
    "        if current_eval_loss < self.best_eval_loss:\n",
    "            self.best_eval_loss = current_eval_loss\n",
    "            self.save_model(self.best_loss_model_dir)\n",
    "            print(f\"Saved best model according to eval_loss: {self.best_eval_loss}\")\n",
    "\n",
    "        if current_eval_accuracy > self.best_eval_accuracy:\n",
    "            self.best_eval_accuracy = current_eval_accuracy\n",
    "            self.save_model(self.best_accuracy_model_dir)\n",
    "            print(f\"Saved best model according to eval_accuracy: {self.best_eval_accuracy}\")\n",
    "\n",
    "        return eval_metrics\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        input_values = inputs.get(\"input_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(input_values=input_values, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest the number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 24)\n",
    "    \n",
    "    # Load the model configuration with the suggested number of layers\n",
    "    config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=num_speakers)\n",
    "    config.num_hidden_layers = num_layers\n",
    "    model = CustomWhisperForSequenceClassification(config)\n",
    "    \n",
    "    # Apply the number of hidden layers correctly\n",
    "    model.whisper.encoder.layers = torch.nn.ModuleList(model.whisper.encoder.layers[:num_layers])\n",
    "    \n",
    "    # Transfer the model to the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        group_by_length=False,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=3,\n",
    "        save_steps=logging_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        learning_rate=1e-5,\n",
    "        save_total_limit=2,\n",
    "        no_cuda=False,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,  # lower eval_loss is better\n",
    "        save_strategy=\"steps\"  # or \"epoch\" if you prefer to save every epoch\n",
    "    )\n",
    "    \n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validate_dataset,\n",
    "        data_collator=DataCollatorForWhisper(),\n",
    "        tokenizer=processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[SaveMetricsCallback(), EarlyStoppingCallback(early_stopping_patience=50)]\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate(validate_dataset)\n",
    "    return metrics['eval_loss']\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=11)\n",
    "\n",
    "result_file = os.path.join(log_dir, \"OptunaResult.txt\")\n",
    "with open(result_file, \"w\") as f:\n",
    "    f.write(\"Best trial:\\n\")\n",
    "    trial = study.best_trial\n",
    "    f.write(f\"  Value: {trial.value}\\n\")\n",
    "    f.write(\"  Params:\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(f\"    {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(\"\\nAll trials:\\n\")\n",
    "    for i, trial in enumerate(study.trials):\n",
    "        f.write(f\"Trial {i}:\\n\")\n",
    "        f.write(f\"  Value: {trial.value}\\n\")\n",
    "        f.write(\"  Params:\\n\")\n",
    "        for key, value in trial.params.items():\n",
    "            f.write(f\"    {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Operation finished.\\n\")\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval zweiter versuch anne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in train: 8880\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in validate: 1110\n",
      "Loaded 111 speakers: {'speaker_6': 0, 'speaker_156': 1, 'speaker_22': 2, 'speaker_19': 3, 'speaker_91': 4, 'speaker_27': 5, 'speaker_94': 6, 'speaker_34': 7, 'speaker_97': 8, 'speaker_100': 9, 'speaker_36': 10, 'speaker_128': 11, 'speaker_134': 12, 'speaker_68': 13, 'speaker_9': 14, 'speaker_17': 15, 'speaker_73': 16, 'speaker_42': 17, 'speaker_52': 18, 'speaker_151': 19, 'speaker_150': 20, 'speaker_141': 21, 'speaker_82': 22, 'speaker_130': 23, 'speaker_75': 24, 'speaker_58': 25, 'speaker_74': 26, 'speaker_104': 27, 'speaker_47': 28, 'speaker_135': 29, 'speaker_71': 30, 'speaker_83': 31, 'speaker_116': 32, 'speaker_99': 33, 'speaker_108': 34, 'speaker_31': 35, 'speaker_106': 36, 'speaker_28': 37, 'speaker_65': 38, 'speaker_48': 39, 'speaker_49': 40, 'speaker_53': 41, 'speaker_3': 42, 'speaker_63': 43, 'speaker_138': 44, 'speaker_98': 45, 'speaker_92': 46, 'speaker_123': 47, 'speaker_32': 48, 'speaker_10': 49, 'speaker_155': 50, 'speaker_153': 51, 'speaker_23': 52, 'speaker_59': 53, 'speaker_56': 54, 'speaker_101': 55, 'speaker_26': 56, 'speaker_30': 57, 'speaker_140': 58, 'speaker_35': 59, 'speaker_93': 60, 'speaker_66': 61, 'speaker_62': 62, 'speaker_137': 63, 'speaker_125': 64, 'speaker_157': 65, 'speaker_13': 66, 'speaker_152': 67, 'speaker_25': 68, 'speaker_89': 69, 'speaker_118': 70, 'speaker_16': 71, 'speaker_70': 72, 'speaker_144': 73, 'speaker_102': 74, 'speaker_43': 75, 'speaker_96': 76, 'speaker_131': 77, 'speaker_87': 78, 'speaker_39': 79, 'speaker_8': 80, 'speaker_51': 81, 'speaker_115': 82, 'speaker_158': 83, 'speaker_107': 84, 'speaker_119': 85, 'speaker_77': 86, 'speaker_2': 87, 'speaker_46': 88, 'speaker_84': 89, 'speaker_126': 90, 'speaker_85': 91, 'speaker_109': 92, 'speaker_11': 93, 'speaker_129': 94, 'speaker_86': 95, 'speaker_121': 96, 'speaker_41': 97, 'speaker_113': 98, 'speaker_76': 99, 'speaker_127': 100, 'speaker_154': 101, 'speaker_120': 102, 'speaker_78': 103, 'speaker_122': 104, 'speaker_117': 105, 'speaker_64': 106, 'speaker_133': 107, 'speaker_80': 108, 'speaker_124': 109, 'speaker_50': 110}\n",
      "Total files in test: 1110\n",
      "Number of unique speakers: 111\n",
      "Labels in train dataset: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110]\n",
      "Labels in test dataset: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110]\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rag/base_venv/lib/python3.10/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "[I 2024-06-22 09:19:34,521] A new study created in memory with name: no-name-18d4997e-cb0a-4b93-8ab9-23f4cbc2f49f\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 1:43:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.893800</td>\n",
       "      <td>4.672912</td>\n",
       "      <td>0.023423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.469100</td>\n",
       "      <td>4.340931</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.277200</td>\n",
       "      <td>4.216887</td>\n",
       "      <td>0.036937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.073800</td>\n",
       "      <td>3.885266</td>\n",
       "      <td>0.049550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.652900</td>\n",
       "      <td>3.464424</td>\n",
       "      <td>0.119820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.322900</td>\n",
       "      <td>3.143207</td>\n",
       "      <td>0.178378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.098700</td>\n",
       "      <td>2.957637</td>\n",
       "      <td>0.200901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>2.940800</td>\n",
       "      <td>2.774390</td>\n",
       "      <td>0.244144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>2.821000</td>\n",
       "      <td>2.657195</td>\n",
       "      <td>0.281081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.672300</td>\n",
       "      <td>2.572147</td>\n",
       "      <td>0.288288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.520300</td>\n",
       "      <td>2.527134</td>\n",
       "      <td>0.291892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.452800</td>\n",
       "      <td>2.389963</td>\n",
       "      <td>0.348649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.337000</td>\n",
       "      <td>2.308143</td>\n",
       "      <td>0.376577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.279500</td>\n",
       "      <td>2.281055</td>\n",
       "      <td>0.379279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.222900</td>\n",
       "      <td>2.244623</td>\n",
       "      <td>0.390090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.672911643981934\n",
      "Saved best model according to eval_accuracy: 0.023423423423423424\n",
      "Saved best model according to eval_loss: 4.340930938720703\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.216886520385742\n",
      "Saved best model according to eval_accuracy: 0.036936936936936934\n",
      "Saved best model according to eval_loss: 3.8852663040161133\n",
      "Saved best model according to eval_accuracy: 0.04954954954954955\n",
      "Saved best model according to eval_loss: 3.4644243717193604\n",
      "Saved best model according to eval_accuracy: 0.11981981981981982\n",
      "Saved best model according to eval_loss: 3.143206834793091\n",
      "Saved best model according to eval_accuracy: 0.1783783783783784\n",
      "Saved best model according to eval_loss: 2.957637071609497\n",
      "Saved best model according to eval_accuracy: 0.2009009009009009\n",
      "Saved best model according to eval_loss: 2.7743895053863525\n",
      "Saved best model according to eval_accuracy: 0.24414414414414415\n",
      "Saved best model according to eval_loss: 2.6571950912475586\n",
      "Saved best model according to eval_accuracy: 0.2810810810810811\n",
      "Saved best model according to eval_loss: 2.5721473693847656\n",
      "Saved best model according to eval_accuracy: 0.2882882882882883\n",
      "Saved best model according to eval_loss: 2.5271341800689697\n",
      "Saved best model according to eval_accuracy: 0.2918918918918919\n",
      "Saved best model according to eval_loss: 2.389963150024414\n",
      "Saved best model according to eval_accuracy: 0.34864864864864864\n",
      "Saved best model according to eval_loss: 2.30814266204834\n",
      "Saved best model according to eval_accuracy: 0.37657657657657656\n",
      "Saved best model according to eval_loss: 2.281054973602295\n",
      "Saved best model according to eval_accuracy: 0.3792792792792793\n",
      "Saved best model according to eval_loss: 2.2446231842041016\n",
      "Saved best model according to eval_accuracy: 0.3900900900900901\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 11:04:32,442] Trial 0 finished with value: 2.2446231842041016 and parameters: {'num_layers': 6}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 1:00:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.833000</td>\n",
       "      <td>4.535194</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.415100</td>\n",
       "      <td>4.326240</td>\n",
       "      <td>0.023423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.273600</td>\n",
       "      <td>4.210543</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.093400</td>\n",
       "      <td>3.889349</td>\n",
       "      <td>0.047748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.667200</td>\n",
       "      <td>3.439522</td>\n",
       "      <td>0.119820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.302500</td>\n",
       "      <td>3.103096</td>\n",
       "      <td>0.198198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.042900</td>\n",
       "      <td>2.905648</td>\n",
       "      <td>0.219820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>2.864400</td>\n",
       "      <td>2.750836</td>\n",
       "      <td>0.259459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>2.770500</td>\n",
       "      <td>2.628991</td>\n",
       "      <td>0.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.636500</td>\n",
       "      <td>2.545605</td>\n",
       "      <td>0.304505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.497600</td>\n",
       "      <td>2.539784</td>\n",
       "      <td>0.298198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.437200</td>\n",
       "      <td>2.403599</td>\n",
       "      <td>0.347748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.370300</td>\n",
       "      <td>2.348627</td>\n",
       "      <td>0.369369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.313900</td>\n",
       "      <td>2.314509</td>\n",
       "      <td>0.372973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.268500</td>\n",
       "      <td>2.289143</td>\n",
       "      <td>0.375676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.535193920135498\n",
      "Saved best model according to eval_accuracy: 0.025225225225225224\n",
      "Saved best model according to eval_loss: 4.326239585876465\n",
      "Saved best model according to eval_loss: 4.210543155670166\n",
      "Saved best model according to eval_accuracy: 0.03333333333333333\n",
      "Saved best model according to eval_loss: 3.8893485069274902\n",
      "Saved best model according to eval_accuracy: 0.047747747747747746\n",
      "Saved best model according to eval_loss: 3.4395222663879395\n",
      "Saved best model according to eval_accuracy: 0.11981981981981982\n",
      "Saved best model according to eval_loss: 3.1030964851379395\n",
      "Saved best model according to eval_accuracy: 0.1981981981981982\n",
      "Saved best model according to eval_loss: 2.9056482315063477\n",
      "Saved best model according to eval_accuracy: 0.21981981981981982\n",
      "Saved best model according to eval_loss: 2.75083589553833\n",
      "Saved best model according to eval_accuracy: 0.2594594594594595\n",
      "Saved best model according to eval_loss: 2.62899112701416\n",
      "Saved best model according to eval_accuracy: 0.2972972972972973\n",
      "Saved best model according to eval_loss: 2.545605421066284\n",
      "Saved best model according to eval_accuracy: 0.3045045045045045\n",
      "Saved best model according to eval_loss: 2.5397844314575195\n",
      "Saved best model according to eval_loss: 2.4035985469818115\n",
      "Saved best model according to eval_accuracy: 0.34774774774774775\n",
      "Saved best model according to eval_loss: 2.3486270904541016\n",
      "Saved best model according to eval_accuracy: 0.36936936936936937\n",
      "Saved best model according to eval_loss: 2.3145086765289307\n",
      "Saved best model according to eval_accuracy: 0.372972972972973\n",
      "Saved best model according to eval_loss: 2.2891428470611572\n",
      "Saved best model according to eval_accuracy: 0.37567567567567567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 12:05:45,995] Trial 1 finished with value: 2.2891428470611572 and parameters: {'num_layers': 3}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 5:18:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.924900</td>\n",
       "      <td>4.785599</td>\n",
       "      <td>0.015315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.533800</td>\n",
       "      <td>4.365416</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.299400</td>\n",
       "      <td>4.282217</td>\n",
       "      <td>0.029730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.170600</td>\n",
       "      <td>4.086433</td>\n",
       "      <td>0.042342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.979700</td>\n",
       "      <td>3.861633</td>\n",
       "      <td>0.045946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.759900</td>\n",
       "      <td>3.556464</td>\n",
       "      <td>0.101802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.509400</td>\n",
       "      <td>3.355268</td>\n",
       "      <td>0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.314800</td>\n",
       "      <td>3.191609</td>\n",
       "      <td>0.155856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.195200</td>\n",
       "      <td>3.050605</td>\n",
       "      <td>0.178378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>3.050800</td>\n",
       "      <td>2.948289</td>\n",
       "      <td>0.186486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.904500</td>\n",
       "      <td>2.890564</td>\n",
       "      <td>0.208108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.828000</td>\n",
       "      <td>2.746595</td>\n",
       "      <td>0.232432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.734900</td>\n",
       "      <td>2.679876</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.672400</td>\n",
       "      <td>2.619864</td>\n",
       "      <td>0.308108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.593300</td>\n",
       "      <td>2.596937</td>\n",
       "      <td>0.312613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.7855987548828125\n",
      "Saved best model according to eval_accuracy: 0.015315315315315315\n",
      "Saved best model according to eval_loss: 4.365415573120117\n",
      "Saved best model according to eval_accuracy: 0.025225225225225224\n",
      "Saved best model according to eval_loss: 4.282217025756836\n",
      "Saved best model according to eval_accuracy: 0.02972972972972973\n",
      "Saved best model according to eval_loss: 4.086432933807373\n",
      "Saved best model according to eval_accuracy: 0.04234234234234234\n",
      "Saved best model according to eval_loss: 3.86163330078125\n",
      "Saved best model according to eval_accuracy: 0.04594594594594595\n",
      "Saved best model according to eval_loss: 3.5564637184143066\n",
      "Saved best model according to eval_accuracy: 0.1018018018018018\n",
      "Saved best model according to eval_loss: 3.3552680015563965\n",
      "Saved best model according to eval_accuracy: 0.13513513513513514\n",
      "Saved best model according to eval_loss: 3.1916091442108154\n",
      "Saved best model according to eval_accuracy: 0.15585585585585585\n",
      "Saved best model according to eval_loss: 3.050605058670044\n",
      "Saved best model according to eval_accuracy: 0.1783783783783784\n",
      "Saved best model according to eval_loss: 2.948289155960083\n",
      "Saved best model according to eval_accuracy: 0.1864864864864865\n",
      "Saved best model according to eval_loss: 2.890564441680908\n",
      "Saved best model according to eval_accuracy: 0.20810810810810812\n",
      "Saved best model according to eval_loss: 2.7465953826904297\n",
      "Saved best model according to eval_accuracy: 0.23243243243243245\n",
      "Saved best model according to eval_loss: 2.6798758506774902\n",
      "Saved best model according to eval_accuracy: 0.2756756756756757\n",
      "Saved best model according to eval_loss: 2.619863748550415\n",
      "Saved best model according to eval_accuracy: 0.3081081081081081\n",
      "Saved best model according to eval_loss: 2.596937417984009\n",
      "Saved best model according to eval_accuracy: 0.31261261261261264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 03:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 17:28:07,354] Trial 2 finished with value: 2.596937417984009 and parameters: {'num_layers': 21}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 4:49:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.920100</td>\n",
       "      <td>4.769555</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.509700</td>\n",
       "      <td>4.347812</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.284400</td>\n",
       "      <td>4.283791</td>\n",
       "      <td>0.027928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.144800</td>\n",
       "      <td>4.072552</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.921800</td>\n",
       "      <td>3.785553</td>\n",
       "      <td>0.055856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.688500</td>\n",
       "      <td>3.507492</td>\n",
       "      <td>0.101802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.472100</td>\n",
       "      <td>3.318033</td>\n",
       "      <td>0.124324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.268000</td>\n",
       "      <td>3.120628</td>\n",
       "      <td>0.142342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.145300</td>\n",
       "      <td>2.970693</td>\n",
       "      <td>0.184685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>3.005300</td>\n",
       "      <td>2.887051</td>\n",
       "      <td>0.199099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.871500</td>\n",
       "      <td>2.848806</td>\n",
       "      <td>0.217117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.802900</td>\n",
       "      <td>2.717357</td>\n",
       "      <td>0.252252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.707400</td>\n",
       "      <td>2.654583</td>\n",
       "      <td>0.285586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.654900</td>\n",
       "      <td>2.605813</td>\n",
       "      <td>0.309009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.591600</td>\n",
       "      <td>2.579988</td>\n",
       "      <td>0.305405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.769554615020752\n",
      "Saved best model according to eval_accuracy: 0.013513513513513514\n",
      "Saved best model according to eval_loss: 4.347812175750732\n",
      "Saved best model according to eval_accuracy: 0.025225225225225224\n",
      "Saved best model according to eval_loss: 4.283790588378906\n",
      "Saved best model according to eval_accuracy: 0.027927927927927927\n",
      "Saved best model according to eval_loss: 4.07255220413208\n",
      "Saved best model according to eval_accuracy: 0.04054054054054054\n",
      "Saved best model according to eval_loss: 3.785552978515625\n",
      "Saved best model according to eval_accuracy: 0.055855855855855854\n",
      "Saved best model according to eval_loss: 3.5074915885925293\n",
      "Saved best model according to eval_accuracy: 0.1018018018018018\n",
      "Saved best model according to eval_loss: 3.318033456802368\n",
      "Saved best model according to eval_accuracy: 0.12432432432432433\n",
      "Saved best model according to eval_loss: 3.1206278800964355\n",
      "Saved best model according to eval_accuracy: 0.14234234234234233\n",
      "Saved best model according to eval_loss: 2.9706931114196777\n",
      "Saved best model according to eval_accuracy: 0.18468468468468469\n",
      "Saved best model according to eval_loss: 2.8870513439178467\n",
      "Saved best model according to eval_accuracy: 0.1990990990990991\n",
      "Saved best model according to eval_loss: 2.848806142807007\n",
      "Saved best model according to eval_accuracy: 0.21711711711711712\n",
      "Saved best model according to eval_loss: 2.7173569202423096\n",
      "Saved best model according to eval_accuracy: 0.25225225225225223\n",
      "Saved best model according to eval_loss: 2.654582977294922\n",
      "Saved best model according to eval_accuracy: 0.2855855855855856\n",
      "Saved best model according to eval_loss: 2.6058127880096436\n",
      "Saved best model according to eval_accuracy: 0.309009009009009\n",
      "Saved best model according to eval_loss: 2.579988479614258\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 03:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-22 22:20:45,927] Trial 3 finished with value: 2.579988479614258 and parameters: {'num_layers': 19}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 3:38:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.915600</td>\n",
       "      <td>4.777668</td>\n",
       "      <td>0.012613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.532200</td>\n",
       "      <td>4.373528</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.296900</td>\n",
       "      <td>4.268996</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.151100</td>\n",
       "      <td>4.041599</td>\n",
       "      <td>0.043243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.909100</td>\n",
       "      <td>3.712463</td>\n",
       "      <td>0.079279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.588600</td>\n",
       "      <td>3.382426</td>\n",
       "      <td>0.126126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.351900</td>\n",
       "      <td>3.219248</td>\n",
       "      <td>0.129730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.137800</td>\n",
       "      <td>3.003518</td>\n",
       "      <td>0.190090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.009900</td>\n",
       "      <td>2.843326</td>\n",
       "      <td>0.237838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.869800</td>\n",
       "      <td>2.747936</td>\n",
       "      <td>0.246847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.734700</td>\n",
       "      <td>2.714047</td>\n",
       "      <td>0.244144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.662500</td>\n",
       "      <td>2.587217</td>\n",
       "      <td>0.283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.571400</td>\n",
       "      <td>2.517804</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.500100</td>\n",
       "      <td>2.480216</td>\n",
       "      <td>0.335135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.452200</td>\n",
       "      <td>2.447228</td>\n",
       "      <td>0.340541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.777667999267578\n",
      "Saved best model according to eval_accuracy: 0.012612612612612612\n",
      "Saved best model according to eval_loss: 4.373528480529785\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.268996238708496\n",
      "Saved best model according to eval_accuracy: 0.03333333333333333\n",
      "Saved best model according to eval_loss: 4.041599273681641\n",
      "Saved best model according to eval_accuracy: 0.043243243243243246\n",
      "Saved best model according to eval_loss: 3.7124626636505127\n",
      "Saved best model according to eval_accuracy: 0.07927927927927927\n",
      "Saved best model according to eval_loss: 3.3824262619018555\n",
      "Saved best model according to eval_accuracy: 0.12612612612612611\n",
      "Saved best model according to eval_loss: 3.2192482948303223\n",
      "Saved best model according to eval_accuracy: 0.12972972972972974\n",
      "Saved best model according to eval_loss: 3.0035183429718018\n",
      "Saved best model according to eval_accuracy: 0.1900900900900901\n",
      "Saved best model according to eval_loss: 2.8433260917663574\n",
      "Saved best model according to eval_accuracy: 0.23783783783783785\n",
      "Saved best model according to eval_loss: 2.7479355335235596\n",
      "Saved best model according to eval_accuracy: 0.24684684684684685\n",
      "Saved best model according to eval_loss: 2.7140467166900635\n",
      "Saved best model according to eval_loss: 2.587216854095459\n",
      "Saved best model according to eval_accuracy: 0.28378378378378377\n",
      "Saved best model according to eval_loss: 2.51780366897583\n",
      "Saved best model according to eval_accuracy: 0.32432432432432434\n",
      "Saved best model according to eval_loss: 2.4802162647247314\n",
      "Saved best model according to eval_accuracy: 0.33513513513513515\n",
      "Saved best model according to eval_loss: 2.447228193283081\n",
      "Saved best model according to eval_accuracy: 0.34054054054054056\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 02:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 02:01:25,734] Trial 4 finished with value: 2.447228193283081 and parameters: {'num_layers': 14}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 2:26:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.895400</td>\n",
       "      <td>4.652500</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.446000</td>\n",
       "      <td>4.330514</td>\n",
       "      <td>0.023423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.277500</td>\n",
       "      <td>4.234533</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.125300</td>\n",
       "      <td>4.059233</td>\n",
       "      <td>0.043243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.866000</td>\n",
       "      <td>3.718048</td>\n",
       "      <td>0.081982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.596700</td>\n",
       "      <td>3.427899</td>\n",
       "      <td>0.117117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.345300</td>\n",
       "      <td>3.184917</td>\n",
       "      <td>0.145045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.160700</td>\n",
       "      <td>3.035941</td>\n",
       "      <td>0.173874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.031000</td>\n",
       "      <td>2.887138</td>\n",
       "      <td>0.220721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.896600</td>\n",
       "      <td>2.776479</td>\n",
       "      <td>0.245946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.751200</td>\n",
       "      <td>2.734310</td>\n",
       "      <td>0.240541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.676500</td>\n",
       "      <td>2.591304</td>\n",
       "      <td>0.287387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.576100</td>\n",
       "      <td>2.526079</td>\n",
       "      <td>0.320721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.515200</td>\n",
       "      <td>2.478696</td>\n",
       "      <td>0.350450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.455800</td>\n",
       "      <td>2.443157</td>\n",
       "      <td>0.355856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.652500152587891\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.330514430999756\n",
      "Saved best model according to eval_loss: 4.234533309936523\n",
      "Saved best model according to eval_accuracy: 0.03423423423423423\n",
      "Saved best model according to eval_loss: 4.05923318862915\n",
      "Saved best model according to eval_accuracy: 0.043243243243243246\n",
      "Saved best model according to eval_loss: 3.718048334121704\n",
      "Saved best model according to eval_accuracy: 0.08198198198198198\n",
      "Saved best model according to eval_loss: 3.4278993606567383\n",
      "Saved best model according to eval_accuracy: 0.11711711711711711\n",
      "Saved best model according to eval_loss: 3.1849169731140137\n",
      "Saved best model according to eval_accuracy: 0.14504504504504503\n",
      "Saved best model according to eval_loss: 3.0359413623809814\n",
      "Saved best model according to eval_accuracy: 0.17387387387387387\n",
      "Saved best model according to eval_loss: 2.8871378898620605\n",
      "Saved best model according to eval_accuracy: 0.22072072072072071\n",
      "Saved best model according to eval_loss: 2.7764785289764404\n",
      "Saved best model according to eval_accuracy: 0.24594594594594596\n",
      "Saved best model according to eval_loss: 2.7343101501464844\n",
      "Saved best model according to eval_loss: 2.591304302215576\n",
      "Saved best model according to eval_accuracy: 0.2873873873873874\n",
      "Saved best model according to eval_loss: 2.5260791778564453\n",
      "Saved best model according to eval_accuracy: 0.3207207207207207\n",
      "Saved best model according to eval_loss: 2.47869610786438\n",
      "Saved best model according to eval_accuracy: 0.3504504504504504\n",
      "Saved best model according to eval_loss: 2.4431569576263428\n",
      "Saved best model according to eval_accuracy: 0.35585585585585583\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 01:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 04:29:18,171] Trial 5 finished with value: 2.4431569576263428 and parameters: {'num_layers': 9}. Best is trial 0 with value: 2.2446231842041016.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 2:40:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.916000</td>\n",
       "      <td>4.783528</td>\n",
       "      <td>0.009009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.546900</td>\n",
       "      <td>4.377087</td>\n",
       "      <td>0.021622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.299900</td>\n",
       "      <td>4.254467</td>\n",
       "      <td>0.035135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.155000</td>\n",
       "      <td>4.073232</td>\n",
       "      <td>0.042342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.916600</td>\n",
       "      <td>3.731267</td>\n",
       "      <td>0.067568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.532800</td>\n",
       "      <td>3.329860</td>\n",
       "      <td>0.151351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.247800</td>\n",
       "      <td>3.137992</td>\n",
       "      <td>0.163964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.038600</td>\n",
       "      <td>2.876686</td>\n",
       "      <td>0.214414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>2.909800</td>\n",
       "      <td>2.753243</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.767000</td>\n",
       "      <td>2.628896</td>\n",
       "      <td>0.280180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.582300</td>\n",
       "      <td>2.584932</td>\n",
       "      <td>0.272072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.495600</td>\n",
       "      <td>2.404184</td>\n",
       "      <td>0.337838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.402000</td>\n",
       "      <td>2.305865</td>\n",
       "      <td>0.367568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.305700</td>\n",
       "      <td>2.256332</td>\n",
       "      <td>0.390991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.217100</td>\n",
       "      <td>2.218705</td>\n",
       "      <td>0.397297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.783527851104736\n",
      "Saved best model according to eval_accuracy: 0.009009009009009009\n",
      "Saved best model according to eval_loss: 4.377086639404297\n",
      "Saved best model according to eval_accuracy: 0.021621621621621623\n",
      "Saved best model according to eval_loss: 4.254466533660889\n",
      "Saved best model according to eval_accuracy: 0.03513513513513514\n",
      "Saved best model according to eval_loss: 4.073232173919678\n",
      "Saved best model according to eval_accuracy: 0.04234234234234234\n",
      "Saved best model according to eval_loss: 3.731267213821411\n",
      "Saved best model according to eval_accuracy: 0.06756756756756757\n",
      "Saved best model according to eval_loss: 3.3298604488372803\n",
      "Saved best model according to eval_accuracy: 0.15135135135135136\n",
      "Saved best model according to eval_loss: 3.1379916667938232\n",
      "Saved best model according to eval_accuracy: 0.16396396396396395\n",
      "Saved best model according to eval_loss: 2.876685619354248\n",
      "Saved best model according to eval_accuracy: 0.21441441441441442\n",
      "Saved best model according to eval_loss: 2.7532429695129395\n",
      "Saved best model according to eval_accuracy: 0.2756756756756757\n",
      "Saved best model according to eval_loss: 2.6288957595825195\n",
      "Saved best model according to eval_accuracy: 0.2801801801801802\n",
      "Saved best model according to eval_loss: 2.584932327270508\n",
      "Saved best model according to eval_loss: 2.404184103012085\n",
      "Saved best model according to eval_accuracy: 0.33783783783783783\n",
      "Saved best model according to eval_loss: 2.3058645725250244\n",
      "Saved best model according to eval_accuracy: 0.3675675675675676\n",
      "Saved best model according to eval_loss: 2.2563321590423584\n",
      "Saved best model according to eval_accuracy: 0.390990990990991\n",
      "Saved best model according to eval_loss: 2.2187047004699707\n",
      "Saved best model according to eval_accuracy: 0.3972972972972973\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 01:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 07:12:08,542] Trial 6 finished with value: 2.2187047004699707 and parameters: {'num_layers': 10}. Best is trial 6 with value: 2.2187047004699707.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 1:57:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.902300</td>\n",
       "      <td>4.728735</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.486100</td>\n",
       "      <td>4.362293</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.285800</td>\n",
       "      <td>4.219041</td>\n",
       "      <td>0.035135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.124500</td>\n",
       "      <td>3.981441</td>\n",
       "      <td>0.044144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.821300</td>\n",
       "      <td>3.631139</td>\n",
       "      <td>0.083784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.462000</td>\n",
       "      <td>3.266313</td>\n",
       "      <td>0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.225400</td>\n",
       "      <td>3.091312</td>\n",
       "      <td>0.177477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.061500</td>\n",
       "      <td>2.908785</td>\n",
       "      <td>0.210811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>2.935300</td>\n",
       "      <td>2.773690</td>\n",
       "      <td>0.256757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.795500</td>\n",
       "      <td>2.661446</td>\n",
       "      <td>0.261261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.636600</td>\n",
       "      <td>2.613597</td>\n",
       "      <td>0.278378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.539500</td>\n",
       "      <td>2.467036</td>\n",
       "      <td>0.322523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.431200</td>\n",
       "      <td>2.388108</td>\n",
       "      <td>0.346847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.373000</td>\n",
       "      <td>2.341468</td>\n",
       "      <td>0.372072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.314100</td>\n",
       "      <td>2.310383</td>\n",
       "      <td>0.372072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.728735446929932\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.362293243408203\n",
      "Saved best model according to eval_loss: 4.219041347503662\n",
      "Saved best model according to eval_accuracy: 0.03513513513513514\n",
      "Saved best model according to eval_loss: 3.981440544128418\n",
      "Saved best model according to eval_accuracy: 0.044144144144144144\n",
      "Saved best model according to eval_loss: 3.631138801574707\n",
      "Saved best model according to eval_accuracy: 0.08378378378378379\n",
      "Saved best model according to eval_loss: 3.266313314437866\n",
      "Saved best model according to eval_accuracy: 0.13513513513513514\n",
      "Saved best model according to eval_loss: 3.0913116931915283\n",
      "Saved best model according to eval_accuracy: 0.17747747747747747\n",
      "Saved best model according to eval_loss: 2.9087846279144287\n",
      "Saved best model according to eval_accuracy: 0.21081081081081082\n",
      "Saved best model according to eval_loss: 2.7736897468566895\n",
      "Saved best model according to eval_accuracy: 0.25675675675675674\n",
      "Saved best model according to eval_loss: 2.6614460945129395\n",
      "Saved best model according to eval_accuracy: 0.26126126126126126\n",
      "Saved best model according to eval_loss: 2.6135973930358887\n",
      "Saved best model according to eval_accuracy: 0.27837837837837837\n",
      "Saved best model according to eval_loss: 2.4670357704162598\n",
      "Saved best model according to eval_accuracy: 0.3225225225225225\n",
      "Saved best model according to eval_loss: 2.3881075382232666\n",
      "Saved best model according to eval_accuracy: 0.34684684684684686\n",
      "Saved best model according to eval_loss: 2.341468095779419\n",
      "Saved best model according to eval_accuracy: 0.37207207207207205\n",
      "Saved best model according to eval_loss: 2.3103833198547363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 01:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 09:11:07,046] Trial 7 finished with value: 2.3103833198547363 and parameters: {'num_layers': 7}. Best is trial 6 with value: 2.2187047004699707.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 3:52:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.918500</td>\n",
       "      <td>4.793799</td>\n",
       "      <td>0.009910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.548900</td>\n",
       "      <td>4.368474</td>\n",
       "      <td>0.024324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.294300</td>\n",
       "      <td>4.249649</td>\n",
       "      <td>0.028829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.123900</td>\n",
       "      <td>4.010673</td>\n",
       "      <td>0.051351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.831400</td>\n",
       "      <td>3.667960</td>\n",
       "      <td>0.075676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.533100</td>\n",
       "      <td>3.375092</td>\n",
       "      <td>0.129730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.313700</td>\n",
       "      <td>3.174528</td>\n",
       "      <td>0.144144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.143200</td>\n",
       "      <td>3.009641</td>\n",
       "      <td>0.172072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.050100</td>\n",
       "      <td>2.903434</td>\n",
       "      <td>0.219820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.919400</td>\n",
       "      <td>2.802516</td>\n",
       "      <td>0.230631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.771300</td>\n",
       "      <td>2.747525</td>\n",
       "      <td>0.246847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.708600</td>\n",
       "      <td>2.619723</td>\n",
       "      <td>0.276577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.603000</td>\n",
       "      <td>2.556057</td>\n",
       "      <td>0.313514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.538100</td>\n",
       "      <td>2.511419</td>\n",
       "      <td>0.316216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.480800</td>\n",
       "      <td>2.479184</td>\n",
       "      <td>0.331532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.793798923492432\n",
      "Saved best model according to eval_accuracy: 0.00990990990990991\n",
      "Saved best model according to eval_loss: 4.36847448348999\n",
      "Saved best model according to eval_accuracy: 0.024324324324324326\n",
      "Saved best model according to eval_loss: 4.249648571014404\n",
      "Saved best model according to eval_accuracy: 0.02882882882882883\n",
      "Saved best model according to eval_loss: 4.010672569274902\n",
      "Saved best model according to eval_accuracy: 0.051351351351351354\n",
      "Saved best model according to eval_loss: 3.6679604053497314\n",
      "Saved best model according to eval_accuracy: 0.07567567567567568\n",
      "Saved best model according to eval_loss: 3.3750922679901123\n",
      "Saved best model according to eval_accuracy: 0.12972972972972974\n",
      "Saved best model according to eval_loss: 3.174527883529663\n",
      "Saved best model according to eval_accuracy: 0.14414414414414414\n",
      "Saved best model according to eval_loss: 3.009641170501709\n",
      "Saved best model according to eval_accuracy: 0.17207207207207206\n",
      "Saved best model according to eval_loss: 2.9034342765808105\n",
      "Saved best model according to eval_accuracy: 0.21981981981981982\n",
      "Saved best model according to eval_loss: 2.802516222000122\n",
      "Saved best model according to eval_accuracy: 0.23063063063063063\n",
      "Saved best model according to eval_loss: 2.7475249767303467\n",
      "Saved best model according to eval_accuracy: 0.24684684684684685\n",
      "Saved best model according to eval_loss: 2.619723081588745\n",
      "Saved best model according to eval_accuracy: 0.2765765765765766\n",
      "Saved best model according to eval_loss: 2.5560572147369385\n",
      "Saved best model according to eval_accuracy: 0.31351351351351353\n",
      "Saved best model according to eval_loss: 2.5114188194274902\n",
      "Saved best model according to eval_accuracy: 0.3162162162162162\n",
      "Saved best model according to eval_loss: 2.47918438911438\n",
      "Saved best model according to eval_accuracy: 0.33153153153153153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 02:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 13:06:47,220] Trial 8 finished with value: 2.47918438911438 and parameters: {'num_layers': 15}. Best is trial 6 with value: 2.2187047004699707.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 2:26:48, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.913500</td>\n",
       "      <td>4.770761</td>\n",
       "      <td>0.016216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.527000</td>\n",
       "      <td>4.370752</td>\n",
       "      <td>0.023423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.300800</td>\n",
       "      <td>4.270798</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.164200</td>\n",
       "      <td>4.071908</td>\n",
       "      <td>0.041441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.905900</td>\n",
       "      <td>3.735035</td>\n",
       "      <td>0.073874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.621100</td>\n",
       "      <td>3.407912</td>\n",
       "      <td>0.117117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.341200</td>\n",
       "      <td>3.184769</td>\n",
       "      <td>0.154054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>2.966790</td>\n",
       "      <td>0.193694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.014200</td>\n",
       "      <td>2.862101</td>\n",
       "      <td>0.227027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.877400</td>\n",
       "      <td>2.760710</td>\n",
       "      <td>0.247748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.720800</td>\n",
       "      <td>2.690811</td>\n",
       "      <td>0.252252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.634300</td>\n",
       "      <td>2.541020</td>\n",
       "      <td>0.302703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.528700</td>\n",
       "      <td>2.462722</td>\n",
       "      <td>0.331532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.461100</td>\n",
       "      <td>2.415986</td>\n",
       "      <td>0.335135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.394400</td>\n",
       "      <td>2.388943</td>\n",
       "      <td>0.354054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.770760536193848\n",
      "Saved best model according to eval_accuracy: 0.016216216216216217\n",
      "Saved best model according to eval_loss: 4.370752334594727\n",
      "Saved best model according to eval_accuracy: 0.023423423423423424\n",
      "Saved best model according to eval_loss: 4.270798206329346\n",
      "Saved best model according to eval_accuracy: 0.03333333333333333\n",
      "Saved best model according to eval_loss: 4.0719075202941895\n",
      "Saved best model according to eval_accuracy: 0.04144144144144144\n",
      "Saved best model according to eval_loss: 3.735034942626953\n",
      "Saved best model according to eval_accuracy: 0.07387387387387387\n",
      "Saved best model according to eval_loss: 3.407912015914917\n",
      "Saved best model according to eval_accuracy: 0.11711711711711711\n",
      "Saved best model according to eval_loss: 3.1847691535949707\n",
      "Saved best model according to eval_accuracy: 0.15405405405405406\n",
      "Saved best model according to eval_loss: 2.966789722442627\n",
      "Saved best model according to eval_accuracy: 0.19369369369369369\n",
      "Saved best model according to eval_loss: 2.8621010780334473\n",
      "Saved best model according to eval_accuracy: 0.22702702702702704\n",
      "Saved best model according to eval_loss: 2.760709762573242\n",
      "Saved best model according to eval_accuracy: 0.24774774774774774\n",
      "Saved best model according to eval_loss: 2.6908106803894043\n",
      "Saved best model according to eval_accuracy: 0.25225225225225223\n",
      "Saved best model according to eval_loss: 2.541019916534424\n",
      "Saved best model according to eval_accuracy: 0.3027027027027027\n",
      "Saved best model according to eval_loss: 2.4627223014831543\n",
      "Saved best model according to eval_accuracy: 0.33153153153153153\n",
      "Saved best model according to eval_loss: 2.4159858226776123\n",
      "Saved best model according to eval_accuracy: 0.33513513513513515\n",
      "Saved best model according to eval_loss: 2.3889431953430176\n",
      "Saved best model according to eval_accuracy: 0.35405405405405405\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 01:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 15:35:25,693] Trial 9 finished with value: 2.3889431953430176 and parameters: {'num_layers': 9}. Best is trial 6 with value: 2.2187047004699707.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 6:01:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.928500</td>\n",
       "      <td>4.804889</td>\n",
       "      <td>0.009009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.577700</td>\n",
       "      <td>4.395104</td>\n",
       "      <td>0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.319500</td>\n",
       "      <td>4.300702</td>\n",
       "      <td>0.027928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.173000</td>\n",
       "      <td>4.101006</td>\n",
       "      <td>0.042342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.989000</td>\n",
       "      <td>3.895713</td>\n",
       "      <td>0.058559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.780700</td>\n",
       "      <td>3.605378</td>\n",
       "      <td>0.109910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.507500</td>\n",
       "      <td>3.368894</td>\n",
       "      <td>0.124324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.322500</td>\n",
       "      <td>3.193270</td>\n",
       "      <td>0.143243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.199300</td>\n",
       "      <td>3.027599</td>\n",
       "      <td>0.187387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>3.079600</td>\n",
       "      <td>2.948883</td>\n",
       "      <td>0.181081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.925400</td>\n",
       "      <td>2.922389</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.845900</td>\n",
       "      <td>2.778533</td>\n",
       "      <td>0.236036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.772900</td>\n",
       "      <td>2.720020</td>\n",
       "      <td>0.263063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.722900</td>\n",
       "      <td>2.680305</td>\n",
       "      <td>0.281081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.647600</td>\n",
       "      <td>2.653056</td>\n",
       "      <td>0.289189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.80488920211792\n",
      "Saved best model according to eval_accuracy: 0.009009009009009009\n",
      "Saved best model according to eval_loss: 4.395103931427002\n",
      "Saved best model according to eval_accuracy: 0.02252252252252252\n",
      "Saved best model according to eval_loss: 4.300702095031738\n",
      "Saved best model according to eval_accuracy: 0.027927927927927927\n",
      "Saved best model according to eval_loss: 4.101006031036377\n",
      "Saved best model according to eval_accuracy: 0.04234234234234234\n",
      "Saved best model according to eval_loss: 3.8957128524780273\n",
      "Saved best model according to eval_accuracy: 0.05855855855855856\n",
      "Saved best model according to eval_loss: 3.605377674102783\n",
      "Saved best model according to eval_accuracy: 0.10990990990990991\n",
      "Saved best model according to eval_loss: 3.368894338607788\n",
      "Saved best model according to eval_accuracy: 0.12432432432432433\n",
      "Saved best model according to eval_loss: 3.193270444869995\n",
      "Saved best model according to eval_accuracy: 0.14324324324324325\n",
      "Saved best model according to eval_loss: 3.027599334716797\n",
      "Saved best model according to eval_accuracy: 0.1873873873873874\n",
      "Saved best model according to eval_loss: 2.948882579803467\n",
      "Saved best model according to eval_loss: 2.922388792037964\n",
      "Saved best model according to eval_accuracy: 0.2\n",
      "Saved best model according to eval_loss: 2.7785332202911377\n",
      "Saved best model according to eval_accuracy: 0.23603603603603604\n",
      "Saved best model according to eval_loss: 2.720020055770874\n",
      "Saved best model according to eval_accuracy: 0.26306306306306304\n",
      "Saved best model according to eval_loss: 2.680305004119873\n",
      "Saved best model according to eval_accuracy: 0.2810810810810811\n",
      "Saved best model according to eval_loss: 2.6530556678771973\n",
      "Saved best model according to eval_accuracy: 0.2891891891891892\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 03:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 21:40:46,945] Trial 10 finished with value: 2.6530556678771973 and parameters: {'num_layers': 24}. Best is trial 6 with value: 2.2187047004699707.\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/rag/base_venv/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13320' max='13320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13320/13320 33:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>888</td>\n",
       "      <td>4.781800</td>\n",
       "      <td>4.664070</td>\n",
       "      <td>0.026126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1776</td>\n",
       "      <td>4.522200</td>\n",
       "      <td>4.403031</td>\n",
       "      <td>0.023423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2664</td>\n",
       "      <td>4.331800</td>\n",
       "      <td>4.276883</td>\n",
       "      <td>0.027928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3552</td>\n",
       "      <td>4.234500</td>\n",
       "      <td>4.164230</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>3.934700</td>\n",
       "      <td>3.726496</td>\n",
       "      <td>0.090991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5328</td>\n",
       "      <td>3.561500</td>\n",
       "      <td>3.415090</td>\n",
       "      <td>0.145045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6216</td>\n",
       "      <td>3.324300</td>\n",
       "      <td>3.215016</td>\n",
       "      <td>0.174775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7104</td>\n",
       "      <td>3.131100</td>\n",
       "      <td>3.058399</td>\n",
       "      <td>0.235135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7992</td>\n",
       "      <td>3.018200</td>\n",
       "      <td>2.937990</td>\n",
       "      <td>0.247748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>2.911500</td>\n",
       "      <td>2.838849</td>\n",
       "      <td>0.273874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9768</td>\n",
       "      <td>2.757500</td>\n",
       "      <td>2.789670</td>\n",
       "      <td>0.256757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10656</td>\n",
       "      <td>2.705900</td>\n",
       "      <td>2.687177</td>\n",
       "      <td>0.308108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11544</td>\n",
       "      <td>2.613700</td>\n",
       "      <td>2.622940</td>\n",
       "      <td>0.339640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12432</td>\n",
       "      <td>2.588100</td>\n",
       "      <td>2.588418</td>\n",
       "      <td>0.345946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13320</td>\n",
       "      <td>2.528300</td>\n",
       "      <td>2.573729</td>\n",
       "      <td>0.358559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model according to eval_loss: 4.664069652557373\n",
      "Saved best model according to eval_accuracy: 0.026126126126126126\n",
      "Saved best model according to eval_loss: 4.403030872344971\n",
      "Saved best model according to eval_loss: 4.276882648468018\n",
      "Saved best model according to eval_accuracy: 0.027927927927927927\n",
      "Saved best model according to eval_loss: 4.164229869842529\n",
      "Saved best model according to eval_accuracy: 0.04054054054054054\n",
      "Saved best model according to eval_loss: 3.7264957427978516\n",
      "Saved best model according to eval_accuracy: 0.09099099099099099\n",
      "Saved best model according to eval_loss: 3.4150896072387695\n",
      "Saved best model according to eval_accuracy: 0.14504504504504503\n",
      "Saved best model according to eval_loss: 3.2150156497955322\n",
      "Saved best model according to eval_accuracy: 0.17477477477477477\n",
      "Saved best model according to eval_loss: 3.058399200439453\n",
      "Saved best model according to eval_accuracy: 0.23513513513513515\n",
      "Saved best model according to eval_loss: 2.9379897117614746\n",
      "Saved best model according to eval_accuracy: 0.24774774774774774\n",
      "Saved best model according to eval_loss: 2.8388490676879883\n",
      "Saved best model according to eval_accuracy: 0.27387387387387385\n",
      "Saved best model according to eval_loss: 2.789670467376709\n",
      "Saved best model according to eval_loss: 2.6871767044067383\n",
      "Saved best model according to eval_accuracy: 0.3081081081081081\n",
      "Saved best model according to eval_loss: 2.6229403018951416\n",
      "Saved best model according to eval_accuracy: 0.3396396396396396\n",
      "Saved best model according to eval_loss: 2.588418483734131\n",
      "Saved best model according to eval_accuracy: 0.34594594594594597\n",
      "Saved best model according to eval_loss: 2.5737287998199463\n",
      "Saved best model according to eval_accuracy: 0.35855855855855856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='139' max='139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [139/139 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-23 22:14:46,593] Trial 11 finished with value: 2.5737287998199463 and parameters: {'num_layers': 1}. Best is trial 6 with value: 2.2187047004699707.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 2.5737287998199463\n",
      "  Params: \n",
      "    num_layers: 1\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback, WhisperConfig, WhisperModel, WhisperProcessor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datasets import load_metric\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up logging for Optuna\n",
    "log_dir = \"/home/rag/experimental_trial/results/training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = os.path.join(log_dir, f\"training_log_optuna_optim_whisper{timestamp}.csv\")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Add file handler to logger\n",
    "file_handler = logging.FileHandler(log_file)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Redirect Optuna logging to the file\n",
    "optuna_logger = logging.getLogger(\"optuna\")\n",
    "optuna_logger.addHandler(file_handler)\n",
    "\n",
    "# Load the processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Define the custom dataset class\n",
    "class LocalAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, subset, noise_factor=0.0, max_speakers=50):\n",
    "        self.processor = processor\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data['subset'] == subset]\n",
    "        \n",
    "        # Limit the number of speakers to max_speakers\n",
    "        speaker_counts = self.data['label'].value_counts()\n",
    "        top_speakers = speaker_counts.nlargest(max_speakers).index\n",
    "        self.data = self.data[self.data['label'].isin(top_speakers)]\n",
    "        \n",
    "        self.speaker_ids = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "        self.data['label'] = self.data['label'].map(self.speaker_ids)\n",
    "        self.noise_factor = noise_factor\n",
    "        \n",
    "        print(f\"Loaded {len(self.speaker_ids)} speakers: {self.speaker_ids}\")\n",
    "        print(f\"Total files in {subset}: {len(self.data)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            audio = librosa.to_mono(audio)\n",
    "            # Use the processor to extract features\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs.input_features.squeeze(0)\n",
    "            return {\"input_values\": input_values, \"labels\": label}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\", file=sys.stderr)\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# Paths to dataset CSV file\n",
    "csv_file = 'dataset_large.csv'\n",
    "train_dataset = LocalAudioDataset(csv_file, processor, 'train', noise_factor=0, max_speakers=111)\n",
    "validate_dataset = LocalAudioDataset(csv_file, processor, 'validate', max_speakers=111)\n",
    "test_dataset = LocalAudioDataset(csv_file, processor, 'test', max_speakers=111)\n",
    "\n",
    "num_speakers = len(train_dataset.speaker_ids)\n",
    "print(f\"Number of unique speakers: {num_speakers}\")\n",
    "\n",
    "print(f\"Labels in train dataset: {train_dataset.data['label'].tolist()}\")\n",
    "print(f\"Labels in test dataset: {test_dataset.data['label'].tolist()}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def validate_labels(dataset):\n",
    "    for item in dataset:\n",
    "        label = item['labels']\n",
    "        if label >= num_speakers or label < 0:\n",
    "            print(f\"Invalid label {label} for item: {item}\")\n",
    "            raise ValueError(f\"Invalid label {label} found in dataset.\")\n",
    "    print(\"All labels are valid.\")\n",
    "\n",
    "batch_size = 2\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "logging_steps = steps_per_epoch // 5\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                step = state.global_step\n",
    "                training_loss = logs.get(\"loss\", \"\")\n",
    "                validation_loss = logs.get(\"eval_loss\", \"\")\n",
    "                accuracy = logs.get(\"eval_accuracy\", \"\")\n",
    "                f.write(f\"{timestamp},{step},{training_loss},{validation_loss},{accuracy}\\n\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=100, early_stopping_threshold=0.0):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric = kwargs.get(\"metrics\", {}).get(\"eval_loss\")\n",
    "        if metric is None:\n",
    "            return\n",
    "        \n",
    "        if self.best_metric is None or metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = metric\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.early_stopping_patience:\n",
    "            print(f\"Early stopping at step {state.global_step}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "# Custom classification head with mean pooling\n",
    "class CustomWhisperForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.whisper = WhisperModel(config)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.hidden_size = config.d_model\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        # Pass input through Whisper encoder\n",
    "        encoder_outputs = self.whisper.encoder(input_values)\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled_output = self.pooling(hidden_states.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Ensure the pooled output has the correct shape\n",
    "        if pooled_output.dim() == 1:\n",
    "            pooled_output = pooled_output.unsqueeze(0)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "# Custom data collator for Whisper\n",
    "class DataCollatorForWhisper:\n",
    "    def __call__(self, features):\n",
    "        input_values = torch.stack([f[\"input_values\"] for f in features])\n",
    "        labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "        return {\"input_values\": input_values, \"labels\": labels}\n",
    "\n",
    "# Extend the Trainer class\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_loss_model_dir = \"./results/best_model_loss_2layer_versuch2\"\n",
    "        self.best_accuracy_model_dir = \"./results/best_model_accuracy_versuch2\"\n",
    "        os.makedirs(self.best_loss_model_dir, exist_ok=True)\n",
    "        os.makedirs(self.best_accuracy_model_dir, exist_ok=True)\n",
    "        self.best_eval_loss = float(\"inf\")\n",
    "        self.best_eval_accuracy = 0.0\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        current_eval_loss = eval_metrics[\"eval_loss\"]\n",
    "        current_eval_accuracy = eval_metrics[\"eval_accuracy\"]\n",
    "        \n",
    "        if current_eval_loss < self.best_eval_loss:\n",
    "            self.best_eval_loss = current_eval_loss\n",
    "            self.save_model(self.best_loss_model_dir)\n",
    "            print(f\"Saved best model according to eval_loss: {self.best_eval_loss}\")\n",
    "\n",
    "        if current_eval_accuracy > self.best_eval_accuracy:\n",
    "            self.best_eval_accuracy = current_eval_accuracy\n",
    "            self.save_model(self.best_accuracy_model_dir)\n",
    "            print(f\"Saved best model according to eval_accuracy: {self.best_eval_accuracy}\")\n",
    "\n",
    "        return eval_metrics\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        input_values = inputs.get(\"input_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(input_values=input_values, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest the number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 24)\n",
    "    \n",
    "    # Load the model configuration with the suggested number of layers\n",
    "    config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=num_speakers)\n",
    "    config.num_hidden_layers = num_layers\n",
    "    model = CustomWhisperForSequenceClassification(config)\n",
    "    \n",
    "    # Apply the number of hidden layers correctly\n",
    "    model.whisper.encoder.layers = torch.nn.ModuleList(model.whisper.encoder.layers[:num_layers])\n",
    "    \n",
    "    # Transfer the model to the correct device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        group_by_length=False,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        num_train_epochs=3,\n",
    "        save_steps=logging_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        logging_steps=logging_steps,\n",
    "        learning_rate=1e-5,\n",
    "        save_total_limit=2,\n",
    "        no_cuda=False,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,  # lower eval_loss is better\n",
    "        save_strategy=\"steps\"  # or \"epoch\" if you prefer to save every epoch\n",
    "    )\n",
    "    \n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=validate_dataset,\n",
    "        data_collator=DataCollatorForWhisper(),\n",
    "        tokenizer=processor,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[SaveMetricsCallback(), EarlyStoppingCallback(early_stopping_patience=50)]\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    metrics = trainer.evaluate(validate_dataset)\n",
    "    return metrics['eval_loss']\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=12)\n",
    "\n",
    "result_file = os.path.join(log_dir, \"OptunaResult.txt\")\n",
    "with open(result_file, \"w\") as f:\n",
    "    f.write(\"Best trial:\\n\")\n",
    "    trial = study.best_trial\n",
    "    f.write(f\"  Value: {trial.value}\\n\")\n",
    "    f.write(\"  Params:\\n\")\n",
    "    for key, value in trial.params.items():\n",
    "        f.write(f\"    {key}: {value}\\n\")\n",
    "    \n",
    "    f.write(\"\\nAll trials:\\n\")\n",
    "    for i, trial in enumerate(study.trials):\n",
    "        f.write(f\"Trial {i}:\\n\")\n",
    "        f.write(f\"  Value: {trial.value}\\n\")\n",
    "        f.write(\"  Params:\\n\")\n",
    "        for key, value in trial.params.items():\n",
    "            f.write(f\"    {key}: {value}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"Operation finished.\\n\")\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback, WhisperConfig, WhisperModel, WhisperProcessor\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datasets import load_metric\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Load the processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Define the custom dataset class\n",
    "class LocalAudioDataset(Dataset):\n",
    "    def __init__(self, csv_file, processor, subset, noise_factor=0.0, max_speakers=50):\n",
    "        self.processor = processor\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.data = self.data[self.data['subset'] == subset]\n",
    "        \n",
    "        # Limit the number of speakers to max_speakers\n",
    "        speaker_counts = self.data['label'].value_counts()\n",
    "        top_speakers = speaker_counts.nlargest(max_speakers).index\n",
    "        self.data = self.data[self.data['label'].isin(top_speakers)]\n",
    "        \n",
    "        self.speaker_ids = {label: idx for idx, label in enumerate(self.data['label'].unique())}\n",
    "        self.data['label'] = self.data['label'].map(self.speaker_ids)\n",
    "        self.noise_factor = noise_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.data.iloc[idx]['path']\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        try:\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            audio = librosa.to_mono(audio)\n",
    "            # Use the processor to extract features\n",
    "            inputs = self.processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs.input_features.squeeze(0)\n",
    "            return {\"input_values\": input_values, \"labels\": label}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\", file=sys.stderr)\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# Paths to dataset CSV file\n",
    "csv_file = 'dataset_large.csv'\n",
    "train_dataset = LocalAudioDataset(csv_file, processor, 'train', noise_factor=0, max_speakers=50)\n",
    "validate_dataset = LocalAudioDataset(csv_file, processor, 'validate', max_speakers=50)\n",
    "test_dataset = LocalAudioDataset(csv_file, processor, 'test', max_speakers=50)\n",
    "\n",
    "num_speakers = len(train_dataset.speaker_ids)\n",
    "print(f\"Number of unique speakers: {num_speakers}\")\n",
    "\n",
    "print(f\"Labels in train dataset: {train_dataset.data['label'].tolist()}\")\n",
    "print(f\"Labels in test dataset: {test_dataset.data['label'].tolist()}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def validate_labels(dataset):\n",
    "    for item in dataset:\n",
    "        label = item['labels']\n",
    "        if label >= num_speakers or label < 0:\n",
    "            print(f\"Invalid label {label} for item: {item}\")\n",
    "            raise ValueError(f\"Invalid label {label} found in dataset.\")\n",
    "    print(\"All labels are valid.\")\n",
    "\n",
    "batch_size = 2\n",
    "steps_per_epoch = math.ceil(len(train_dataset) / batch_size)\n",
    "logging_steps = steps_per_epoch // 5\n",
    "eval_steps = steps_per_epoch // 5\n",
    "\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "log_dir = \"/home/rag/experimental_trial/results/training_logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_file = os.path.join(log_dir, f\"training_log_versuch2_2layer{timestamp}.csv\")\n",
    "with open(log_file, \"w\") as f:\n",
    "    f.write(\"Timestamp,Step,Training Loss,Validation Loss,Accuracy\\n\")\n",
    "\n",
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            with open(log_file, \"a\") as f:\n",
    "                timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                step = state.global_step\n",
    "                training_loss = logs.get(\"loss\", \"\")\n",
    "                validation_loss = logs.get(\"eval_loss\", \"\")\n",
    "                accuracy = logs.get(\"eval_accuracy\", \"\")\n",
    "                f.write(f\"{timestamp},{step},{training_loss},{validation_loss},{accuracy}\\n\")\n",
    "\n",
    "class EarlyStoppingCallback(TrainerCallback):\n",
    "    def __init__(self, early_stopping_patience=100, early_stopping_threshold=0.0):\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.best_metric = None\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metric = kwargs.get(\"metrics\", {}).get(\"eval_loss\")\n",
    "        if metric is None:\n",
    "            return\n",
    "        \n",
    "        if self.best_metric is None or metric < self.best_metric - self.early_stopping_threshold:\n",
    "            self.best_metric = metric\n",
    "            self.patience_counter = 0\n",
    "        else:\n",
    "            self.patience_counter += 1\n",
    "        \n",
    "        if self.patience_counter >= self.early_stopping_patience:\n",
    "            print(f\"Early stopping at step {state.global_step}\")\n",
    "            control.should_training_stop = True\n",
    "\n",
    "# Custom classification head with mean pooling\n",
    "class CustomWhisperForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.whisper = WhisperModel(config)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.hidden_size = config.d_model\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        # Pass input through Whisper encoder\n",
    "        encoder_outputs = self.whisper.encoder(input_values)\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled_output = self.pooling(hidden_states.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Ensure the pooled output has the correct shape\n",
    "        if pooled_output.dim() == 1:\n",
    "            pooled_output = pooled_output.unsqueeze(0)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "# Custom data collator for Whisper\n",
    "class DataCollatorForWhisper:\n",
    "    def __call__(self, features):\n",
    "        input_values = torch.stack([f[\"input_values\"] for f in features])\n",
    "        labels = torch.tensor([f[\"labels\"] for f in features], dtype=torch.long)\n",
    "        return {\"input_values\": input_values, \"labels\": labels}\n",
    "\n",
    "# Extend the Trainer class\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_loss_model_dir = \"./results/best_model_loss_2layer_versuch2\"\n",
    "        self.best_accuracy_model_dir = \"./results/best_model_accuracy_versuch2\"\n",
    "        os.makedirs(self.best_loss_model_dir, exist_ok=True)\n",
    "        os.makedirs(self.best_accuracy_model_dir, exist_ok=True)\n",
    "        self.best_eval_loss = float(\"inf\")\n",
    "        self.best_eval_accuracy = 0.0\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        eval_metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        current_eval_loss = eval_metrics[\"eval_loss\"]\n",
    "        current_eval_accuracy = eval_metrics[\"eval_accuracy\"]\n",
    "        \n",
    "        if current_eval_loss < self.best_eval_loss:\n",
    "            self.best_eval_loss = current_eval_loss\n",
    "            self.save_model(self.best_loss_model_dir)\n",
    "            print(f\"Saved best model according to eval_loss: {self.best_eval_loss}\")\n",
    "\n",
    "        if current_eval_accuracy > self.best_eval_accuracy:\n",
    "            self.best_eval_accuracy = current_eval_accuracy\n",
    "            self.save_model(self.best_accuracy_model_dir)\n",
    "            print(f\"Saved best model according to eval_accuracy: {self.best_eval_accuracy}\")\n",
    "\n",
    "        return eval_metrics\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        input_values = inputs.get(\"input_values\")\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(input_values=input_values, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Load the model configuration with all layers\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=num_speakers)\n",
    "model = CustomWhisperForSequenceClassification(config)\n",
    "\n",
    "# Transfer the model to the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    group_by_length=False,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    num_train_epochs=20,\n",
    "    save_steps=logging_steps,\n",
    "    eval_steps=eval_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=1e-5,\n",
    "    save_total_limit=2,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,  # lower eval_loss is better\n",
    "    save_strategy=\"steps\"  # or \"epoch\" if you prefer to save every epoch\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validate_dataset,\n",
    "    data_collator=DataCollatorForWhisper(),\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[SaveMetricsCallback(), EarlyStoppingCallback(early_stopping_patience=50)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "metrics = trainer.evaluate(validate_dataset)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 50/50 [00:19<00:00,  2.52it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.04it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.97it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.02it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.94it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.95it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.01it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.04it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.03it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  3.00it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.97it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.97it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.99it/s]\n",
      "100%|██████████| 50/50 [00:16<00:00,  2.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperConfig, WhisperModel\n",
    "from safetensors.torch import load_file as safe_load\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the custom classification head with mean pooling for Whisper\n",
    "class CustomWhisperForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.whisper = WhisperModel(config)\n",
    "        self.pooling = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.hidden_size = config.d_model\n",
    "        self.num_labels = config.num_labels\n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.num_labels)\n",
    "\n",
    "    def forward(self, input_values, attention_mask=None, labels=None):\n",
    "        # Pass input through Whisper encoder\n",
    "        encoder_outputs = self.whisper.encoder(input_values)\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled_output = self.pooling(hidden_states.transpose(1, 2)).squeeze(-1)\n",
    "        \n",
    "        # Ensure the pooled output has the correct shape\n",
    "        if pooled_output.dim() == 1:\n",
    "            pooled_output = pooled_output.unsqueeze(0)\n",
    "        \n",
    "        # Pass through classifier\n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        \n",
    "        return (loss, logits) if loss is not None else (logits,)\n",
    "\n",
    "# Path to the fine-tuned model weights file\n",
    "model_path = \"/home/rag/experimental_trial/results/best_model_loss_whisper_110/model.safetensors\"\n",
    "\n",
    "# Load the pre-trained Whisper large model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "\n",
    "# Load the model configuration\n",
    "config = WhisperConfig.from_pretrained(\"openai/whisper-large\", num_labels=110)  # Adjust num_labels as needed\n",
    "\n",
    "# Initialize the custom model with the configuration\n",
    "model = CustomWhisperForSequenceClassification(config)\n",
    "\n",
    "# Load the model weights from safetensors file\n",
    "state_dict = safe_load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "def check_directories_exist(directory, layer_indices):\n",
    "    \"\"\"Prüft, ob die benötigten Verzeichnisse für jede Schicht bereits existieren.\"\"\"\n",
    "    all_exist = True\n",
    "    for index in layer_indices:\n",
    "        layer_dir = os.path.join(directory, f\"layer_{index}\")\n",
    "        if not os.path.exists(layer_dir):\n",
    "            all_exist = False\n",
    "            break\n",
    "    return all_exist\n",
    "\n",
    "def load_audio_files(input_directory, output_directory, layer_indices=[-1]):\n",
    "    \"\"\"Lädt alle MP3-Dateien im angegebenen Verzeichnis und extrahiert die Repräsentationen aus den spezifizierten Schichten.\"\"\"\n",
    "    for filename in tqdm(os.listdir(input_directory)):\n",
    "        if filename.endswith(\".mp3\"):\n",
    "            file_path = os.path.join(input_directory, filename)\n",
    "            audio, sr = librosa.load(file_path, sr=16000)\n",
    "            inputs = processor(audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "            input_values = inputs[\"input_features\"].to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model.whisper.encoder(input_values, output_hidden_states=True)\n",
    "                for index in layer_indices:\n",
    "                    hidden_states = outputs.hidden_states[index]\n",
    "                    mean_pooled_hidden_states = hidden_states.mean(dim=1)  # Mean Pooling über die Zeitdimension\n",
    "                    # creating sub directory for each layer in output directory\n",
    "                    layer_dir = os.path.join(output_directory, f\"layer_{index}\")\n",
    "                    os.makedirs(layer_dir, exist_ok=True)\n",
    "                    save_path = os.path.join(layer_dir, f\"{os.path.splitext(filename)[0]}_layer_{index}.npy\")\n",
    "                    np.save(save_path, mean_pooled_hidden_states.cpu().numpy())\n",
    "\n",
    "def process_audio_directory(input_base_directory, output_base_directory, layer_indices=range(25)):\n",
    "    \"\"\"Verarbeitet Audio-Dateien in den angegebenen Verzeichnissen und speichert die Ergebnisse im Zielverzeichnis.\"\"\"\n",
    "    for d in os.listdir(input_base_directory):\n",
    "        input_dir_path = os.path.join(input_base_directory, d)\n",
    "        output_dir_path = os.path.join(output_base_directory, d)\n",
    "        if os.path.isdir(input_dir_path) and not check_directories_exist(output_dir_path, layer_indices):\n",
    "            load_audio_files(input_dir_path, output_dir_path, layer_indices)\n",
    "\n",
    "input_directory_path = os.path.expanduser(\"/home/rag/experimental_trial/data/all_speakers_backup\")\n",
    "output_directory_path = os.path.expanduser(\"/home/rag/experimental_trial/data/all_speakers_whisper_finetuned2\")\n",
    "process_audio_directory(input_directory_path, output_directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
