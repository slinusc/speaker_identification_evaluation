{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QPaqHFMlETRA","executionInfo":{"status":"ok","timestamp":1716733284935,"user_tz":-120,"elapsed":146623,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"cfbbf258-1cc2-490b-9e2b-bec07a5ae01b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data for speaker 1 from /content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker1\n","Loading data for speaker 2 from /content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker2\n","Loading data for speaker 3 from /content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker3\n","Total samples loaded: 150\n","Shape of Y after one-hot encoding: (150, 3)\n"]}],"source":["import numpy as np\n","import os\n","import torch\n","from sklearn.preprocessing import OneHotEncoder\n","from tqdm import tqdm\n","\n","def load_and_process_embeddings(speaker_dir, num_layers=25, max_samples=50, m_max=100):\n","    embeddings = [[] for _ in range(num_layers)]\n","    for layer in range(num_layers):\n","        layer_dir = os.path.join(speaker_dir, f\"layer_{layer}\")\n","        layer_files = sorted(os.listdir(layer_dir))[:max_samples]\n","        for file in layer_files:\n","            file_path = os.path.join(layer_dir, file)\n","            embedding = np.load(file_path)  # Shape: (1024, m)\n","            if embedding.shape[1] < m_max:\n","                padded_embedding = np.pad(embedding, ((0, 0), (0, m_max - embedding.shape[1])), 'constant')\n","            else:\n","                padded_embedding = embedding[:, :m_max]\n","            embeddings[layer].append(padded_embedding.flatten())  # Flatten to 1D\n","    return [np.array(embeddings[layer]) for layer in range(num_layers)]\n","\n","def cca_cpu(X, Y_batch, reg=1e-4):\n","    X_mean = np.mean(X, axis=0)\n","    Y_mean = np.mean(Y_batch, axis=0)\n","    X_centered = X - X_mean\n","    Y_centered = Y_batch - Y_mean\n","\n","    cov_XY = np.dot(X_centered.T, Y_centered) / (X.shape[0] - 1)\n","    cov_XX = np.dot(X_centered.T, X_centered) / (X.shape[0] - 1) + reg * np.eye(X_centered.shape[1])\n","    cov_YY = np.dot(Y_centered.T, Y_centered) / (Y_batch.shape[0] - 1) + reg * np.eye(Y_centered.shape[1])\n","\n","    eigvals, eigvecs = np.linalg.eig(np.dot(np.linalg.inv(cov_XX), np.dot(cov_XY, np.dot(np.linalg.inv(cov_YY), cov_XY.T))))\n","\n","    return np.mean(np.real(eigvals[-min(X.shape[1], Y_batch.shape[1]):]))\n","\n","# Main script\n","speaker_dirs = [\n","    \"/content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker1\",\n","    \"/content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker2\",\n","    \"/content/drive/MyDrive/enhancing_speaker_recognition_evaluation/data/speaker3\"\n","]\n","\n","X_layers = [[] for _ in range(25)]\n","y = []\n","\n","for i, speaker_dir in enumerate(speaker_dirs):\n","    print(f\"Loading data for speaker {i+1} from {speaker_dir}\")\n","    speaker_embeddings = load_and_process_embeddings(speaker_dir, num_layers=25, max_samples=50, m_max=100)\n","    for layer in range(25):\n","        X_layers[layer].extend(speaker_embeddings[layer])\n","    y.extend([i] * len(speaker_embeddings[0]))\n","\n","y = np.array(y)\n","print(f\"Total samples loaded: {len(y)}\")\n","\n","encoder = OneHotEncoder()\n","Y = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n","print(f\"Shape of Y after one-hot encoding: {Y.shape}\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1v0Y4QckIf40","colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"status":"error","timestamp":1716734317143,"user_tz":-120,"elapsed":6,"user":{"displayName":"Linus Stuhlmann","userId":"07279173608860907824"}},"outputId":"1a5ccaa4-a95b-4f6b-a222-122d1a70ef27"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tqdm' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-c4e78e35ffce>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcanonical_correlations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Processing Layers\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcanonical_correlations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"]}],"source":["canonical_correlations = []\n","for layer in tqdm(range(25), desc=\"Processing Layers\"):\n","    X_layer = np.array(X_layers[layer])\n","    if X_layer.shape[0] == 0:\n","        canonical_correlations.append(0)\n","        continue\n","\n","    layer_correlations = []\n","    num_batches = X_layer.shape[0] // 2  # Reducing batch size to 2\n","    for i in range(num_batches):\n","        X_batch = X_layer[i*2:(i+1)*2]\n","        Y_batch = Y[i*2:(i+1)*2]\n","\n","        if np.var(X_batch) == 0 or np.var(Y_batch) == 0:\n","            print(f\"Zero variance in batch {i} for layer {layer+1}. Skipping.\")\n","            continue\n","\n","        correlation = cca_cpu(X_batch, Y_batch)\n","        layer_correlations.append(correlation)\n","\n","    if layer_correlations:\n","        canonical_correlations.append(np.mean(layer_correlations))\n","    else:\n","        canonical_correlations.append(0)\n","\n","    # Free up memory\n","    del X_layer\n","    del X_batch\n","    del Y_batch\n","    torch.cuda.empty_cache()\n","\n","best_layer_index = np.argmax(canonical_correlations)\n","print(f'The layer with the highest canonical correlation is Layer {best_layer_index + 1}')\n","\n","print(\"Canonical Correlation Values for each layer:\")\n","for i, correlation in enumerate(canonical_correlations):\n","    print(f\"Layer {i+1}: {correlation}\")\n","\n","import matplotlib.pyplot as plt\n","plt.plot(range(1, 26), canonical_correlations, marker='o')\n","plt.xlabel('Layer')\n","plt.ylabel('Canonical Correlation')\n","plt.title('Canonical Correlation by Layer')\n","plt.show()"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"178kKOS4t38Jf_M7WsNojiKjYlxnXEXSQ","authorship_tag":"ABX9TyPGV6fppBMRxB/99dVU6eZj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}