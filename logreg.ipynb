{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Function to load hidden states and labels from npy files\n",
    "def load_test_train(root_dir, speakers, layer, max_files_per_speaker=50):\n",
    "    hidden_states_list = []\n",
    "    labels_list = []\n",
    "    speaker_to_label = {speaker: idx for idx, speaker in enumerate(speakers)}\n",
    "    \n",
    "    for speaker in tqdm(speakers):\n",
    "        layer_path = os.path.join(root_dir, speaker, f'layer_{layer}')\n",
    "        file_paths = glob.glob(os.path.join(layer_path, '*.npy'))[:max_files_per_speaker]\n",
    "        for file_path in file_paths:\n",
    "            hidden_states = np.load(file_path)\n",
    "            if hidden_states.ndim == 3 and hidden_states.shape[0] == 1 and hidden_states.shape[2] == 1024:\n",
    "                hidden_states = hidden_states.squeeze(0)  # Remove the unnecessary dimension\n",
    "                labels = speaker_to_label[speaker]  # Generate labels from speaker ID\n",
    "                hidden_states_list.append(hidden_states)\n",
    "                labels_list.append(labels)\n",
    "            else:\n",
    "                print(f\"Unexpected shape {hidden_states.shape} for file {file_path}, skipping.\")\n",
    "    \n",
    "    # Pad hidden states to the maximum length\n",
    "    max_length = max(hidden_states.shape[0] for hidden_states in hidden_states_list)\n",
    "    padded_hidden_states_list = [np.pad(hidden_states, ((0, max_length - hidden_states.shape[0]), (0, 0)), mode='constant') for hidden_states in hidden_states_list]\n",
    "    \n",
    "    return np.array(padded_hidden_states_list), np.array(labels_list)\n",
    "\n",
    "# Logistic Regression model with PyTorch\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.linear(x)\n",
    "        return outputs\n",
    "\n",
    "# Example speakers and number of layers\n",
    "root_dir = '/home/rag/experimental_trial/data/all_speakers_xlrs_new_28_05' \n",
    "speakers = ['speaker_' + str(i) for i in range(1, 51)]\n",
    "num_layers = 25  # Example number of layers\n",
    "\n",
    "results = []\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "for i in range(num_layers):\n",
    "    print(f\"Processing layer {i}\")\n",
    "    hidden_states_layer, labels_layer = load_test_train(root_dir, speakers, i)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(hidden_states_layer, labels_layer, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Verify labels\n",
    "    num_classes = len(np.unique(y_train))\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Move data to GPU if available\n",
    "    X_train = X_train.to(device)\n",
    "    y_train = y_train.to(device)\n",
    "    X_test = X_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "\n",
    "    # Initialize model\n",
    "    input_dim = X_train.shape[1] * X_train.shape[2]  # Number of features after flattening\n",
    "    output_dim = num_classes  # Number of classes\n",
    "    model = LogisticRegressionModel(input_dim, output_dim).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Early stopping parameters\n",
    "    best_loss = float('inf')\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train.view(X_train.size(0), -1))  # Flatten the inputs\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Early stopping check\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_test.view(X_test.size(0), -1))\n",
    "            val_loss = criterion(val_outputs, y_test).item()\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test.view(X_test.size(0), -1)).argmax(dim=1)\n",
    "    \n",
    "    y_test_cpu = y_test.cpu().numpy()\n",
    "    y_pred_cpu = y_pred.cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_test_cpu, y_pred_cpu)\n",
    "    prec = precision_score(y_test_cpu, y_pred_cpu, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test_cpu, y_pred_cpu, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test_cpu, y_pred_cpu, average='weighted', zero_division=0)\n",
    "   \n",
    "    results.append({'layer': i, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "    print(f\"Layer {i} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/logreg_50_xlsr_es.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without GPU turned out to achive higher results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 - Accuracy: 0.9020, Precision: 0.9179, Recall: 0.9020, F1: 0.9021\n",
      "Processing layer 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 - Accuracy: 0.8940, Precision: 0.9150, Recall: 0.8940, F1: 0.8953\n",
      "Processing layer 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 2 - Accuracy: 0.9340, Precision: 0.9434, Recall: 0.9340, F1: 0.9345\n",
      "Processing layer 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 3 - Accuracy: 0.9260, Precision: 0.9381, Recall: 0.9260, F1: 0.9248\n",
      "Processing layer 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 4 - Accuracy: 0.9260, Precision: 0.9403, Recall: 0.9260, F1: 0.9255\n",
      "Processing layer 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 5 - Accuracy: 0.9140, Precision: 0.9247, Recall: 0.9140, F1: 0.9142\n",
      "Processing layer 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 6 - Accuracy: 0.9260, Precision: 0.9334, Recall: 0.9260, F1: 0.9266\n",
      "Processing layer 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 7 - Accuracy: 0.9080, Precision: 0.9156, Recall: 0.9080, F1: 0.9070\n",
      "Processing layer 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 8 - Accuracy: 0.8580, Precision: 0.8698, Recall: 0.8580, F1: 0.8555\n",
      "Processing layer 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 9 - Accuracy: 0.8260, Precision: 0.8529, Recall: 0.8260, F1: 0.8276\n",
      "Processing layer 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 10 - Accuracy: 0.8100, Precision: 0.8285, Recall: 0.8100, F1: 0.8085\n",
      "Processing layer 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 11 - Accuracy: 0.7660, Precision: 0.8034, Recall: 0.7660, F1: 0.7665\n",
      "Processing layer 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 12 - Accuracy: 0.7220, Precision: 0.7688, Recall: 0.7220, F1: 0.7271\n",
      "Processing layer 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:26<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 13 - Accuracy: 0.7340, Precision: 0.7888, Recall: 0.7340, F1: 0.7364\n",
      "Processing layer 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 14 - Accuracy: 0.6640, Precision: 0.7327, Recall: 0.6640, F1: 0.6683\n",
      "Processing layer 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 15 - Accuracy: 0.6460, Precision: 0.7147, Recall: 0.6460, F1: 0.6517\n",
      "Processing layer 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:24<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 16 - Accuracy: 0.6700, Precision: 0.7137, Recall: 0.6700, F1: 0.6757\n",
      "Processing layer 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:25<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 17 - Accuracy: 0.6560, Precision: 0.7278, Recall: 0.6560, F1: 0.6628\n",
      "Processing layer 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:24<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 18 - Accuracy: 0.6440, Precision: 0.7109, Recall: 0.6440, F1: 0.6538\n",
      "Processing layer 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:14<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 19 - Accuracy: 0.5740, Precision: 0.6293, Recall: 0.5740, F1: 0.5741\n",
      "Processing layer 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:23<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 20 - Accuracy: 0.4200, Precision: 0.4515, Recall: 0.4200, F1: 0.4153\n",
      "Processing layer 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:23<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 21 - Accuracy: 0.3420, Precision: 0.3737, Recall: 0.3420, F1: 0.3425\n",
      "Processing layer 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 22 - Accuracy: 0.2720, Precision: 0.2875, Recall: 0.2720, F1: 0.2664\n",
      "Processing layer 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 23 - Accuracy: 0.2640, Precision: 0.3126, Recall: 0.2640, F1: 0.2669\n",
      "Processing layer 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:16<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 24 - Accuracy: 0.3040, Precision: 0.3297, Recall: 0.3040, F1: 0.2909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Function to load hidden states and labels from npy files\n",
    "def load_test_train(root_dir, speakers, layer, max_files_per_speaker=50):\n",
    "    hidden_states_list = []\n",
    "    labels_list = []\n",
    "    speaker_to_label = {speaker: idx for idx, speaker in enumerate(speakers)}\n",
    "    \n",
    "    for speaker in tqdm(speakers):\n",
    "        layer_path = os.path.join(root_dir, speaker, f'layer_{layer}')\n",
    "        file_paths = glob.glob(os.path.join(layer_path, '*.npy'))[:max_files_per_speaker]\n",
    "        for file_path in file_paths:\n",
    "            hidden_states = np.load(file_path)\n",
    "            if hidden_states.ndim == 3 and hidden_states.shape[0] == 1 and hidden_states.shape[2] == 1024:\n",
    "                hidden_states = hidden_states.squeeze(0)  # Remove the unnecessary dimension\n",
    "                labels = speaker_to_label[speaker]  # Generate labels from speaker ID\n",
    "                hidden_states_list.append(hidden_states)\n",
    "                labels_list.append(labels)\n",
    "            else:\n",
    "                print(f\"Unexpected shape {hidden_states.shape} for file {file_path}, skipping.\")\n",
    "    \n",
    "    # Pad hidden states to the maximum length\n",
    "    max_length = max(hidden_states.shape[0] for hidden_states in hidden_states_list)\n",
    "    padded_hidden_states_list = [np.pad(hidden_states, ((0, max_length - hidden_states.shape[0]), (0, 0)), mode='constant') for hidden_states in hidden_states_list]\n",
    "    \n",
    "    return np.array(padded_hidden_states_list), np.array(labels_list)\n",
    "\n",
    "# Example speakers and number of layers\n",
    "root_dir = '/home/rag/experimental_trial/data/all_speakers_w2vec_28.05' \n",
    "speakers = ['speaker_' + str(i) for i in range(1, 51)]\n",
    "num_layers = 25  # Example number of layers\n",
    "\n",
    "results = []\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "for i in range(num_layers):\n",
    "    print(f\"Processing layer {i}\")\n",
    "    hidden_states_layer, labels_layer = load_test_train(root_dir, speakers, i)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(hidden_states_layer, labels_layer, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Flatten the inputs\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    # Initialize and train the logistic regression model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "   \n",
    "    results.append({'layer': i, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "    print(f\"Layer {i} - Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "results_df.to_csv('results/logreg_50_w2v_cpu.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
